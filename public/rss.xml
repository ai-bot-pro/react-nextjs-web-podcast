<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" version="2.0"><channel><title>AI Podcast</title><link>https://weedge.us.kg</link><description>Latest podcasts about AI.</description><language>en-us</language><itunes:image href="https://weedge.us.kg/favicon.ico" /><image><url>https://weedge.us.kg/favicon.ico</url><title>AI Podcast</title><link>https://weedge.us.kg</link></image><item><title>large language model</title><description>introduce large language model</description><link>https://weedge.us.kg/podcast/0a6c9d4fd4054ca0adafa59c6ee2b4e1</link><guid>https://weedge.us.kg/podcast/0a6c9d4fd4054ca0adafa59c6ee2b4e1</guid><pubDate>Tue, 08 Oct 2024 09:00:00 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/LLM.mp3" length="973389" type="audio/mpeg" /><itunes:duration>04:03</itunes:duration></item><item><title>apple iOS 18 All New Features Sept 2024</title><description /><link>https://weedge.us.kg/podcast/46c61e163aa0404e85abd2c511e1c4cb</link><guid>https://weedge.us.kg/podcast/46c61e163aa0404e85abd2c511e1c4cb</guid><pubDate>Fri, 25 Oct 2024 20:50:06 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/iOS_18_All_New_Features_Sept_2024.mp3" length="3291309" type="audio/mpeg" /><itunes:duration>13:42</itunes:duration></item><item><title>CUDA Mode Keynote Andrej Karpathy</title><description /><link>https://weedge.us.kg/podcast/0652c5ca3336447b9dddf4c7016fd6a9</link><guid>https://weedge.us.kg/podcast/0652c5ca3336447b9dddf4c7016fd6a9</guid><pubDate>Fri, 25 Oct 2024 21:10:10 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/CUDA-Mode-Keynote-Andrej Karpathy.mp3" length="2034285" type="audio/mpeg" /><itunes:duration>08:28</itunes:duration></item><item><title>AI Radio FM - 技术频道: 大型语言模型</title><description>欢迎来到 AI Radio FM - 技术频道，你的个人生成式 AI 播客。今天，我们将深入探讨大型语言模型，一种旨在处理自然语言处理任务（如语言生成）的强大计算模型。</description><link>https://weedge.us.kg/podcast/db33f70ace07483b8ebbd27b890f356b</link><guid>https://weedge.us.kg/podcast/db33f70ace07483b8ebbd27b890f356b</guid><pubDate>Sun, 27 Oct 2024 19:16:25 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/Large_language_model_2024-10-27_19-15-28.mp3" length="628365" type="audio/mpeg" /><itunes:duration>02:36</itunes:duration></item><item><title>AI 广播电台 - 技术频道: 深入了解大型语言模型</title><description>欢迎收听 AI 广播电台 - 技术频道，您的个人生成式 AI 播客。今天，我们将深入讨论大型语言模型，这种强大的工具正在改变我们与语言互动的方式。准备好深入了解这些模型的工作原理、它们的潜力以及它们的局限性吧！</description><link>https://weedge.us.kg/podcast/092b64820378454695f5b0e7174c0451</link><guid>https://weedge.us.kg/podcast/092b64820378454695f5b0e7174c0451</guid><pubDate>Sun, 27 Oct 2024 19:47:07 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/Large_language_model_2024-10-27_19-45-19.mp3" length="976461" type="audio/mpeg" /><itunes:duration>04:04</itunes:duration></item><item><title>AI 广播电台 - 技术频道: 大型语言模型</title><description>欢迎收听 AI 广播电台 - 技术频道，您的个人生成式 AI 播客。今天，我们将深入探讨大型语言模型 - 这些令人难以置信的 AI 系统如何彻底改变自然语言处理，以及它们对我们世界的意义。</description><link>https://weedge.us.kg/podcast/ec3775b1e6a348f8934e27f48e4c7d42</link><guid>https://weedge.us.kg/podcast/ec3775b1e6a348f8934e27f48e4c7d42</guid><pubDate>Sun, 27 Oct 2024 21:24:02 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/Large_language_model_2024-10-27_21-22-30.mp3" length="806253" type="audio/mpeg" /><itunes:duration>03:21</itunes:duration></item><item><title>从PyTorch到LLM.C - Andrej Karpathy谈论他的LLM冒险</title><description>欢迎收听 AI Radio FM - Technology Channel！今天，我们很荣幸邀请到 Andrej Karpathy，一位在 AI 领域拥有超过十年经验的传奇人物，来和我们聊聊他的 LLM 项目 - llm.c。Andrej 将带我们回顾 LMC 的诞生过程，从最初的 PyTorch 困境到最终使用 C 和 CUDA 语言实现高效训练，并分享他对 LLM 未来发展趋势的洞察。 项目地址： https://github.com/karpathy/llm.c</description><link>https://weedge.us.kg/podcast/28e49876ca9f425ebb6d5824030d8e0b</link><guid>https://weedge.us.kg/podcast/28e49876ca9f425ebb6d5824030d8e0b</guid><pubDate>Sun, 27 Oct 2024 21:51:15 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/aR6CzM0x-g0_2024-10-27_21-42-29.mp3" length="4245549" type="audio/mpeg" /><itunes:duration>17:41</itunes:duration></item><item><title>AI Radio FM - Technology Channel: iOS 18 新功能介绍</title><description>加入我们一起探索 iOS 18 带来的激动人心的新功能！从增强型 Apple Intelligence 到全新的 Image Playground 应用，以及重新设计的 Photos 和 Maps 应用，我们将深入探讨这些功能如何改变你使用 iPhone 的方式。</description><link>https://weedge.us.kg/podcast/9eace677de97498ca0ca4b51ef64f47b</link><guid>https://weedge.us.kg/podcast/9eace677de97498ca0ca4b51ef64f47b</guid><pubDate>Sun, 27 Oct 2024 22:22:16 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/iOS_18_All_New_Features_Sept_2024.pdf_2024-10-27_22-19-05.mp3" length="1065453" type="audio/mpeg" /><itunes:duration>04:26</itunes:duration></item><item><title>AI Radio FM - 科技频道：揭秘 Hugging Face</title><description>欢迎来到 AI Radio FM - 科技频道，您的个人生成式 AI 播客！今天，我们将深入探讨一家改变机器学习领域的公司——Hugging Face。</description><link>https://weedge.us.kg/podcast/79f3288665034ce1a2ce2b6a9a53d809</link><guid>https://weedge.us.kg/podcast/79f3288665034ce1a2ce2b6a9a53d809</guid><pubDate>Mon, 28 Oct 2024 18:20:12 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/Hugging_Face_2024-10-28_18-18-51.mp3" length="654957" type="audio/mpeg" /><itunes:duration>02:43</itunes:duration></item><item><title>AI Radio FM - 科技频道: OmniParser - 纯视觉GUI代理的未来</title><description>欢迎收听AI Radio FM - 科技频道，您的个人生成式AI播客！今天，我们将深入探讨OmniParser，一个改变了纯视觉GUI代理游戏规则的技术。加入我们，与我们的专家一起揭开OmniParser的奥秘，它如何利用强大的视觉语言模型来理解用户界面，并为各种应用和平台带来革命性的自动化的可能性。</description><link>https://weedge.us.kg/podcast/d8940dffd8f54739be766298a2f81960</link><guid>https://weedge.us.kg/podcast/d8940dffd8f54739be766298a2f81960</guid><pubDate>Tue, 29 Oct 2024 11:56:14 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2408.00203_2024-10-29_11-54-27.mp3" length="920109" type="audio/mpeg" /><itunes:duration>03:49</itunes:duration></item><item><title>AI 电台 FM - 科技频道: GPT-4o 的语音革命</title><description>探索 OpenAI 的最新突破， GPT-4o 带来的语音革命！本期节目将深入探讨 GPT-4o 的语音理解和生成能力，以及它带来的安全挑战、伦理问题和广泛的社会影响。</description><link>https://weedge.us.kg/podcast/ec10e73eb18f4be5b3a9814d96e56a1a</link><guid>https://weedge.us.kg/podcast/ec10e73eb18f4be5b3a9814d96e56a1a</guid><pubDate>Tue, 29 Oct 2024 12:20:02 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2410.21276_2024-10-29_12-17-59.mp3" length="1039341" type="audio/mpeg" /><itunes:duration>04:19</itunes:duration></item><item><title>AI Radio FM - Paper Read Channel: Infinite-LLM: Efficient LLM Service for Long Context</title><description>欢迎收听AI Radio FM - Paper Read Channel，您的个人生成式 AI 播客。今天，我们将讨论一篇关于 Infinite-LLM 的有趣论文，该论文提出了一种新的 LLM 服务系统，旨在有效地处理动态上下文长度。让我们深入探讨！</description><link>https://weedge.us.kg/podcast/5951bbb300f24ce79e11a1b19a83d5df</link><guid>https://weedge.us.kg/podcast/5951bbb300f24ce79e11a1b19a83d5df</guid><pubDate>Tue, 29 Oct 2024 14:04:35 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2401.02669.mp3" length="1136973" type="audio/mpeg" /><itunes:duration>04:52</itunes:duration></item><item><title>AI Radio FM - Technology Channel: 聊聊 Cohere 如何助力加拿大初创生态系统</title><description>本期 AI Radio FM - Technology Channel 邀请了 Cohere 的联合创始人 Ivan 来讨论 Cohere 如何助力加拿大初创生态系统，以及他对 AI 技术的未来看法。</description><link>https://weedge.us.kg/podcast/7ead264767ef47da98a70ca99d9d4c55</link><guid>https://weedge.us.kg/podcast/7ead264767ef47da98a70ca99d9d4c55</guid><pubDate>Thu, 31 Oct 2024 21:49:05 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/I0PLTzeEbtg_2024-10-31_21-45-49.mp3" length="2242893" type="audio/mpeg" /><itunes:duration>09:20</itunes:duration></item><item><title>AI 广播电台 - 科技频道：Freeze-Omni：一个智能且低延迟的语音到语音对话模型</title><description>欢迎收听 AI 广播电台 - 科技频道，您的个人生成式 AI 播客！今天，我们将深入探讨 Freeze-Omni，这是一个拥有冻结 LLM 的智能且低延迟语音到语音对话模型。准备好迎接一场关于大型语言模型、语音编码器和解码器、以及双向对话设计的令人兴奋的旅程吧！</description><link>https://weedge.us.kg/podcast/2037f3952dbf469f9581d13bedb2f622</link><guid>https://weedge.us.kg/podcast/2037f3952dbf469f9581d13bedb2f622</guid><pubDate>Sat, 09 Nov 2024 21:04:52 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2411.00774_2024-11-09_21-02-58.mp3" length="1318221" type="audio/mpeg" /><itunes:duration>05:29</itunes:duration></item><item><title>AI Radio FM - Technology Channel: StoryAgent - Customized Storytelling Video Generation via Multi-Agent Collaboration</title><description>Welcome to AI Radio FM - Technology Channel,  Your Personal Generative AI Podcast! Today, we&amp;#x27;re diving into the world of StoryAgent, a groundbreaking multi-agent framework for creating customized storytelling videos. Join us as we explore the innovative techniques behind this technology and discuss its potential to revolutionize video production.</description><link>https://weedge.us.kg/podcast/449568ea328d4ea98f14238c0bad4591</link><guid>https://weedge.us.kg/podcast/449568ea328d4ea98f14238c0bad4591</guid><pubDate>Sat, 09 Nov 2024 21:29:21 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2411.04925_2024-11-09_21-27-39.mp3" length="867693" type="audio/mpeg" /><itunes:duration>03:36</itunes:duration></item><item><title>AI 广播电台 - 科技频道：探索 Mini-Omni2，开源的 GPT-4o 多模态语言模型</title><description>欢迎收听 AI 广播电台 - 科技频道，您的个人生成式 AI 播客！今天我们将深入探讨一个激动人心的主题：Mini-Omni2，它是一个旨在模拟 GPT-4o 功能的开源多模态语言模型。加入我们，一起探索这个具有视觉、语音、文本和双向交互能力的强大模型。</description><link>https://weedge.us.kg/podcast/7c9501116d45404090dd3392d09a2ebd</link><guid>https://weedge.us.kg/podcast/7c9501116d45404090dd3392d09a2ebd</guid><pubDate>Sat, 09 Nov 2024 22:06:14 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2410.11190v3_2024-11-09_22-04-50.mp3" length="786669" type="audio/mpeg" /><itunes:duration>03:16</itunes:duration></item><item><title>AI 广播电台 - 科技频道 - 开源 PDF 转码工具 Docling 深度解析</title><description>欢迎收听 AI 广播电台 - 科技频道，您的个人生成式 AI 播客！今天，我们将深入探讨 Docling，一个开源的 PDF 文档转换工具。我们将会探索其背后的技术细节，包括它如何利用先进的 AI 模型来理解文档布局，并将其转换为可读的格式，以及它在不同应用场景中的潜力。加入我们，深入了解 Docling 如何改变我们处理 PDF 文档的方式！</description><link>https://weedge.us.kg/podcast/abcbbf67416f46bb95b1c5c911ff7baa</link><guid>https://weedge.us.kg/podcast/abcbbf67416f46bb95b1c5c911ff7baa</guid><pubDate>Sat, 09 Nov 2024 22:09:09 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2408.09869v3_2024-11-09_22-08-00.mp3" length="845421" type="audio/mpeg" /><itunes:duration>03:31</itunes:duration></item><item><title>AI Radio FM - Technology Channel: Hunyuan3D-1.0 的革命性3D生成框架</title><description>欢迎收听 AI Radio FM - 科技频道，您的个人生成式 AI 播客！今天，我们深入探讨了腾讯 HunYuan3D-1.0 的最新突破，一个将文本和图像转化为逼真 3D 模型的统一框架。加入我们，一起揭秘其背后的奥秘，并了解这项技术如何改变游戏、电影和电子商务等领域。</description><link>https://weedge.us.kg/podcast/69a9b789c64c44d4bf4a5f61e39559d1</link><guid>https://weedge.us.kg/podcast/69a9b789c64c44d4bf4a5f61e39559d1</guid><pubDate>Sat, 09 Nov 2024 22:22:13 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2411.02293v2_2024-11-09_22-19-55.mp3" length="1099629" type="audio/mpeg" /><itunes:duration>04:34</itunes:duration></item><item><title>AI 广播电台 - 科技频道：混合Transformer模型，多模态基础模型的稀疏且可扩展架构</title><description>欢迎收听 AI 广播电台 - 科技频道，您的个人生成式 AI 播客！在今天的节目中，我们将深入探讨一项关于混合Transformer模型（MoT）的有趣内容，它是一种稀疏且可扩展的架构，专门为多模态基础模型而设计。MoT 通过将非嵌入参数按模态分离，并保留对多模态序列的全局自注意力，从而优化了模态特定处理，同时保留了跨模态交互。让我们一起探索 MoT 的优势和应用吧！</description><link>https://weedge.us.kg/podcast/6bfc1fa8fc664f35a296484894ddb5b7</link><guid>https://weedge.us.kg/podcast/6bfc1fa8fc664f35a296484894ddb5b7</guid><pubDate>Sat, 09 Nov 2024 22:45:07 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/Mixture-of-Transformers- A Sparse and Scalable Architecture for Multi-Modal Foundation Models.pdf_2024-11-09_22-43-51.mp3" length="890061" type="audio/mpeg" /><itunes:duration>03:42</itunes:duration></item><item><title>AI Radio FM - 技术频道：SVDQuant：低秩组件吸收异常值以实现 4 位扩散模型</title><description>欢迎收听 AI Radio FM - 技术频道，您的个人生成式 AI 播客。今天，我们将探讨一篇关于使用低秩组件吸收异常值以实现 4 位扩散模型的有趣论文。让我们深入研究！</description><link>https://weedge.us.kg/podcast/0c069cc161044d699e666244a27edf0f</link><guid>https://weedge.us.kg/podcast/0c069cc161044d699e666244a27edf0f</guid><pubDate>Sun, 10 Nov 2024 10:11:15 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2411.05007v1_2024-11-10_10-09-55.mp3" length="778701" type="audio/mpeg" /><itunes:duration>03:14</itunes:duration></item><item><title>AI Radio FM - Technology Channel: LLM × MapReduce: Simplified Long-Sequence Processing Using Large Language Models</title><description>在这个激动人心的 AI Radio FM - 技术频道播客中，我们将深入探讨一项名为 LLM × MapReduce 的突破性技术，该技术可以简化处理超长文本序列。加入我们，聆听来自人工智能领域的专家们对这项技术带来的挑战和解决方案的精彩讨论。</description><link>https://weedge.us.kg/podcast/c25886529f864447a1e8f07f9aabc068</link><guid>https://weedge.us.kg/podcast/c25886529f864447a1e8f07f9aabc068</guid><pubDate>Sun, 10 Nov 2024 10:19:31 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2410.09342v1_2024-11-10_10-17-56.mp3" length="1007085" type="audio/mpeg" /><itunes:duration>04:11</itunes:duration></item><item><title>AI 广播电台 - 科技频道：超越文本：为工业应用优化多模态 RAG</title><description>欢迎收听 AI 广播电台 - 科技频道，您的个人生成式 AI  播客。今天，我们将讨论一篇关于利用多模态输入来优化 RAG 并将其应用于工业领域的有趣论文。让我们深入探讨！</description><link>https://weedge.us.kg/podcast/8c49dd9f8bc7412fa520ca0635ebaf93</link><guid>https://weedge.us.kg/podcast/8c49dd9f8bc7412fa520ca0635ebaf93</guid><pubDate>Sun, 10 Nov 2024 13:01:22 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2410.21943v1_2024-11-10_12-59-56.mp3" length="903309" type="audio/mpeg" /><itunes:duration>03:45</itunes:duration></item><item><title>HourVideo: 评估一小时视频语言理解能力的新基准数据集</title><description>HourVideo 是一个新颖的基准数据集，旨在严格评估多模态模型对一小时视频的理解能力。该数据集包含一个新的任务套件，包括摘要、感知（回忆、跟踪）、视觉推理（空间、时间、预测、因果、反事实）和导航（房间到房间、对象检索）任务。HourVideo 包含来自 Ego4D 数据集的 500 个手动策划的以自我为中心的视频，时长从 20 分钟到 120 分钟不等，并包含 12,976 个高质量的五选一多项选择问题。</description><link>https://weedge.us.kg/podcast/fdaa00932b584002ad251a021ce5ba1b</link><guid>https://weedge.us.kg/podcast/fdaa00932b584002ad251a021ce5ba1b</guid><pubDate>Sun, 10 Nov 2024 14:36:53 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/HourVideo- 1-Hour Video-Language Understanding.pdf_2024-11-10_14-35-39.mp3" length="776397" type="audio/mpeg" /><itunes:duration>03:13</itunes:duration></item><item><title>AI电台FM - 科技频道：Moshi - 实时对话的语音-文本基础模型</title><description>欢迎来到AI电台FM - 科技频道，您的个性化生成式AI播客。今天，我们将深入探讨Moshi，一个实时对话的语音-文本基础模型，它克服了传统对话系统的局限性。Moshi通过直接在音频域中进行理解和生成来消除文本瓶颈，并利用底层文本LLM的知识和推理能力。它采用了一种流式、分层架构，理论延迟仅为160毫秒，并率先引入了多流音频语言模型，可以处理各种对话动态。此外，Moshi还引入了“内心独白”方法，显著提高了生成的语音的语言质量和真实性。加入我们，一起探索Moshi如何改变人机交互的未来。</description><link>https://weedge.us.kg/podcast/95755aca400745bb91326ec06f1031b2</link><guid>https://weedge.us.kg/podcast/95755aca400745bb91326ec06f1031b2</guid><pubDate>Sun, 10 Nov 2024 18:57:51 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2410.00037v2_2024-11-10_18-55-43.mp3" length="944877" type="audio/mpeg" /><itunes:duration>03:56</itunes:duration></item><item><title>AI Radio FM - Technology Channel: 神经网络中的知识蒸馏</title><description>欢迎收听 AI Radio FM - Technology Channel，您的个人生成式 AI 播客！今天我们将深入探讨神经网络中知识蒸馏的奇妙世界，这是一项技术，可以将大型模型的知识转移到更小的模型中，从而提高效率和性能。</description><link>https://weedge.us.kg/podcast/4e9df53bcfd54551b10a8ea835c4cead</link><guid>https://weedge.us.kg/podcast/4e9df53bcfd54551b10a8ea835c4cead</guid><pubDate>Wed, 13 Nov 2024 12:34:33 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/1503.02531_2024-11-13_12-32-50.mp3" length="889101" type="audio/mpeg" /><itunes:duration>03:42</itunes:duration></item><item><title>AI 广播 FM - 科技频道: 精度缩放定律</title><description>欢迎来到 AI 广播 FM - 科技频道，您的个人生成式 AI 播客。今天，我们将深入探讨一个关于大语言模型精度缩放定律的有趣内容。我们将会讨论训练和推理过程中不同精度对模型性能的影响，以及这些影响与模型参数和数据规模之间的关系。</description><link>https://weedge.us.kg/podcast/438770209b0f4a6e80e5ad03b0802c4f</link><guid>https://weedge.us.kg/podcast/438770209b0f4a6e80e5ad03b0802c4f</guid><pubDate>Thu, 14 Nov 2024 21:36:14 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2411.04330v1_2024-11-14_21-34-27.mp3" length="992973" type="audio/mpeg" /><itunes:duration>04:08</itunes:duration></item><item><title>AI Radio FM - 深度学习GPU推荐</title><description>探讨2023年最佳深度学习GPU，涵盖GPU架构、性能、性价比等多个方面。</description><link>https://weedge.us.kg/podcast/78afda2d398244329ab5477a16864161</link><guid>https://weedge.us.kg/podcast/78afda2d398244329ab5477a16864161</guid><pubDate>Tue, 19 Nov 2024 12:23:40 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/which-gpu-for-deep-learning_2024-11-19_12-22-15.mp3" length="924429" type="audio/mpeg" /><itunes:duration>03:51</itunes:duration></item><item><title>AI Radio FM - Machete: Hopper GPU 优化 GEMM 内核</title><description>深度探讨Neural Magic的Machete内核，专为NVIDIA Hopper GPU上的混合输入量化而优化，显著提升大型语言模型推理性能。</description><link>https://weedge.us.kg/podcast/26f5b9c595e241abaa08deab681e5111</link><guid>https://weedge.us.kg/podcast/26f5b9c595e241abaa08deab681e5111</guid><pubDate>Tue, 19 Nov 2024 13:30:10 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/introducing-machete-a-mixed-input-gemm-kernel-optimized-for-nvidia-hopper-gpus_2024-11-19_13-28-42.mp3" length="773709" type="audio/mpeg" /><itunes:duration>03:13</itunes:duration></item><item><title>AI电台FM科技频道：超小型多模态AI智能体Octopus v3技术详解</title><description>本期节目深入探讨Octopus v3，一款参数小于10亿的、可在边缘设备上运行的多模态AI智能体。我们将与专家一起，从技术细节到实际应用，全方位解读这款令人兴奋的AI创新。</description><link>https://weedge.us.kg/podcast/5ba0f061fb88483b80c184249744d14d</link><guid>https://weedge.us.kg/podcast/5ba0f061fb88483b80c184249744d14d</guid><pubDate>Thu, 21 Nov 2024 16:46:59 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2404.11459v2_2024-11-21_16-45-19.mp3" length="652941" type="audio/mpeg" /><itunes:duration>02:43</itunes:duration></item><item><title>AI电台FM科技频道：生成式AI提示工程技术详解</title><description>本期节目深入探讨生成式人工智能的提示工程技术，涵盖文本、图像、多模态等多种提示方法，并对提示工程的实际应用、安全性和挑战进行全面分析。</description><link>https://weedge.us.kg/podcast/4370b83cbc604ce883423c645f000129</link><guid>https://weedge.us.kg/podcast/4370b83cbc604ce883423c645f000129</guid><pubDate>Thu, 21 Nov 2024 22:08:51 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2406.06608v3_2024-11-21_22-05-59.mp3" length="1133517" type="audio/mpeg" /><itunes:duration>04:43</itunes:duration></item><item><title>AI Radio FM - Auto-RAG: 自动迭代检索的未来</title><description>深度探讨Auto-RAG模型，揭秘其自主迭代检索的机制，以及在知识密集型任务中的卓越表现。</description><link>https://weedge.us.kg/podcast/f5d4b07d9e5645f4aaa93e63dd051977</link><guid>https://weedge.us.kg/podcast/f5d4b07d9e5645f4aaa93e63dd051977</guid><pubDate>Wed, 04 Dec 2024 23:58:29 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2411.19443_2024-12-04_23-56-52.mp3" length="730893" type="audio/mpeg" /><itunes:duration>03:02</itunes:duration></item><item><title>AI电台FM科技频道：HunyuanVideo大型视频生成模型深度解析</title><description>欢迎收听AI电台FM科技频道，本期节目将深入探讨腾讯Hunyuuan团队最新发布的开源视频生成模型HunyuanVideo。我们将从数据处理、模型架构、训练策略以及实际应用等多个角度，全面解读这一具有突破性意义的模型。</description><link>https://weedge.us.kg/podcast/989d2071166441b2bc7244cbfce60fb8</link><guid>https://weedge.us.kg/podcast/989d2071166441b2bc7244cbfce60fb8</guid><pubDate>Thu, 05 Dec 2024 10:22:51 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/hunyuanvideo.pdf_2024-12-05_10-21-14.mp3" length="1173741" type="audio/mpeg" /><itunes:duration>04:53</itunes:duration></item><item><title>AI电台FM科技频道：AGI之路上的里程碑</title><description>探索人工智能通用智能（AGI）的等级框架，探讨其能力、风险和人机交互。</description><link>https://weedge.us.kg/podcast/806081d0f0d844cc94c829331eb2a3ed</link><guid>https://weedge.us.kg/podcast/806081d0f0d844cc94c829331eb2a3ed</guid><pubDate>Tue, 10 Dec 2024 11:02:06 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2311.02462_2024-12-10_11-00-16.mp3" length="958797" type="audio/mpeg" /><itunes:duration>03:59</itunes:duration></item><item><title>AI电台FM科技频道：扩散模型设计基础详解</title><description>本期节目深入探讨扩散模型的三个核心组件：前向过程、反向过程和采样过程，并分析各种设计选择及其影响。我们将讨论噪声配置、转移链、网络架构、反向均值参数化、优化设计、指导机制和加速技术等关键方面。</description><link>https://weedge.us.kg/podcast/960c44edf44f49f29797e9805f1190de</link><guid>https://weedge.us.kg/podcast/960c44edf44f49f29797e9805f1190de</guid><pubDate>Tue, 10 Dec 2024 11:23:32 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2306.04542_2024-12-10_11-21-32.mp3" length="1119309" type="audio/mpeg" /><itunes:duration>04:39</itunes:duration></item><item><title>AI电台FM科技频道：变分自动编码器深度解析</title><description>本期节目深入探讨变分自动编码器（Variational Autoencoder，VAE）的原理和应用，带你揭秘高效近似推断和学习的奥秘。我们将一步步拆解VAE的核心概念，包括随机变分推断、SGVB估计器、AEVB算法等，并结合实际案例进行讲解。</description><link>https://weedge.us.kg/podcast/e73c099ce6fe49849375a4c4b52e4518</link><guid>https://weedge.us.kg/podcast/e73c099ce6fe49849375a4c4b52e4518</guid><pubDate>Tue, 10 Dec 2024 11:57:30 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/1312.6114_2024-12-10_11-56-10.mp3" length="747501" type="audio/mpeg" /><itunes:duration>03:06</itunes:duration></item><item><title>AI电台FM科技频道：Diffusion Transformers 革命性图像生成</title><description>本期节目深入探讨Diffusion Transformers (DiTs) 如何在图像生成领域取得突破性进展，并超越现有U-Net模型。我们将分析DiTs的可扩展性，以及其在ImageNet 512x512和256x256基准测试中如何达到最先进的FID分数。</description><link>https://weedge.us.kg/podcast/1ed63b4f3b1c4b3c8d12f3077c1cba9f</link><guid>https://weedge.us.kg/podcast/1ed63b4f3b1c4b3c8d12f3077c1cba9f</guid><pubDate>Tue, 10 Dec 2024 12:10:26 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2212.09748_2024-12-10_12-08-54.mp3" length="845613" type="audio/mpeg" /><itunes:duration>03:31</itunes:duration></item><item><title>AI Radio FM -  视觉Transformer：图像识别的革命</title><description>深度探讨Vision Transformer (ViT) 如何颠覆图像识别领域，以及其在大型数据集上的卓越表现。</description><link>https://weedge.us.kg/podcast/cc37c1b660ca437da0d5c74679b3ca66</link><guid>https://weedge.us.kg/podcast/cc37c1b660ca437da0d5c74679b3ca66</guid><pubDate>Tue, 10 Dec 2024 12:34:03 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2010.11929_2024-12-10_12-32-19.mp3" length="671853" type="audio/mpeg" /><itunes:duration>02:47</itunes:duration></item><item><title>AI电台FM科技频道：高分辨率图像合成与潜在扩散模型</title><description>本期节目深入探讨高分辨率图像合成技术，特别是潜在扩散模型（LDM）的最新进展。我们将讨论LDM如何通过降低计算复杂度，在高分辨率图像生成领域取得突破性进展，并分析其在图像修复、超分辨率和文本到图像合成等任务中的应用。</description><link>https://weedge.us.kg/podcast/709dc79538bf48339a0487c1a4c5c969</link><guid>https://weedge.us.kg/podcast/709dc79538bf48339a0487c1a4c5c969</guid><pubDate>Tue, 10 Dec 2024 12:43:49 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2112.10752_2024-12-10_12-41-56.mp3" length="906957" type="audio/mpeg" /><itunes:duration>03:46</itunes:duration></item><item><title>AI电台FM科技频道：视频扩散模型综述</title><description>本期节目深入探讨了AI内容生成领域中视频扩散模型的最新进展，涵盖视频生成、编辑和理解三大方向。</description><link>https://weedge.us.kg/podcast/5faafe503b924aeebb0d3688d3958703</link><guid>https://weedge.us.kg/podcast/5faafe503b924aeebb0d3688d3958703</guid><pubDate>Tue, 10 Dec 2024 22:51:01 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2310.10647v2_2024-12-10_22-49-00.mp3" length="848589" type="audio/mpeg" /><itunes:duration>03:32</itunes:duration></item><item><title>AI Radio FM - GLM-4-Voice: 人工智能语音聊天机器人</title><description>深度探讨GLM-4-Voice，一款支持中英双语、具备实时语音对话能力，并根据用户指令调整语音语调、语速和方言等细微差别的智能语音聊天机器人。</description><link>https://weedge.us.kg/podcast/149acf766b654bf3bf5153fa81a70772</link><guid>https://weedge.us.kg/podcast/149acf766b654bf3bf5153fa81a70772</guid><pubDate>Thu, 12 Dec 2024 11:34:53 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/GLM4-voice.pdf_2024-12-12_11-33-17.mp3" length="787533" type="audio/mpeg" /><itunes:duration>03:16</itunes:duration></item><item><title>AI电台FM科技频道：多模态大型语言模型综述</title><description>本期节目深入探讨多模态大型语言模型（MLLM）的最新进展，涵盖架构、训练策略、数据、评估方法以及未来发展方向。我们将与专家一起，揭秘MLLM如何理解和推理多模态信息，以及如何应对多模态幻觉等挑战。</description><link>https://weedge.us.kg/podcast/91ef449ca96d49b7a6599a2ed9c3f8cd</link><guid>https://weedge.us.kg/podcast/91ef449ca96d49b7a6599a2ed9c3f8cd</guid><pubDate>Thu, 12 Dec 2024 12:46:59 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2306.13549v4_2024-12-12_12-45-32.mp3" length="863565" type="audio/mpeg" /><itunes:duration>03:35</itunes:duration></item><item><title>AI电台FM科技频道：多模态大型语言模型评估的全面综述</title><description>本期节目深入探讨多模态大型语言模型（MLLMs）的评估方法，涵盖基准测试类型、基准构建流程、评估方法以及未来发展方向。我们将与专家一起，解读MLLMs评估的挑战和机遇。</description><link>https://weedge.us.kg/podcast/61c0096f24484ee49fc54ddf858cf3e8</link><guid>https://weedge.us.kg/podcast/61c0096f24484ee49fc54ddf858cf3e8</guid><pubDate>Thu, 12 Dec 2024 13:02:42 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2411.15296v2_2024-12-12_13-01-14.mp3" length="733389" type="audio/mpeg" /><itunes:duration>03:03</itunes:duration></item><item><title>AI电台FM科技频道：生成对抗网络GANs深度解析</title><description>本期节目深入探讨Ian Goodfellow等人在2014年提出的生成对抗网络（GANs），揭秘其原理、优势及应用，带你领略AI领域的最新突破。</description><link>https://weedge.us.kg/podcast/99da6a8a39854608ba442322b347ddb1</link><guid>https://weedge.us.kg/podcast/99da6a8a39854608ba442322b347ddb1</guid><pubDate>Thu, 12 Dec 2024 15:54:41 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/1406.2661_2024-12-12_15-52-56.mp3" length="781869" type="audio/mpeg" /><itunes:duration>03:15</itunes:duration></item><item><title>Gemini 2.0 新纪元：智能体时代的到来</title><description>谷歌推出了 Gemini 2.0，一款为智能体时代打造的全新 AI 模型。本次播客将深入探讨 Gemini 2.0 的特性、应用以及谷歌在人工智能领域的最新进展。</description><link>https://weedge.us.kg/podcast/99d3bcfbda67458586d491b820feb265</link><guid>https://weedge.us.kg/podcast/99d3bcfbda67458586d491b820feb265</guid><pubDate>Thu, 12 Dec 2024 17:07:16 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/google-gemini-ai-update-december-2024_2024-12-12_17-05-17.mp3" length="1417581" type="audio/mpeg" /><itunes:duration>05:54</itunes:duration></item><item><title>Gemini 2.0 Flash for Developers</title><description>A podcast discussing the new Gemini 2.0 Flash model and its capabilities for developers.</description><link>https://weedge.us.kg/podcast/4abdac0b126745c6b2e904e5e845db5e</link><guid>https://weedge.us.kg/podcast/4abdac0b126745c6b2e904e5e845db5e</guid><pubDate>Thu, 12 Dec 2024 17:13:08 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/the-next-chapter-of-the-gemini-era-for-developers_2024-12-12_17-10-50.mp3" length="1537677" type="audio/mpeg" /><itunes:duration>06:24</itunes:duration></item><item><title>AI 广播 FM - 技术频道，您的个人生成式人工智能播客</title><description>本期节目我们深入探讨了 POINTS1.5，一个在真实世界应用中表现出色的视觉语言模型。</description><link>https://weedge.us.kg/podcast/26a104b8d79c4515ba7215999c626677</link><guid>https://weedge.us.kg/podcast/26a104b8d79c4515ba7215999c626677</guid><pubDate>Sat, 14 Dec 2024 21:16:08 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2412.08443v1_2024-12-14_21-13-16.mp3" length="1242477" type="audio/mpeg" /><itunes:duration>05:10</itunes:duration></item><item><title>Wavelet Flow VAE for Latent Video Diffusion Models</title><description>A podcast discussion about Wavelet Flow VAE (WF-VAE), a novel autoencoder that leverages multi-level wavelet transforms to enhance video encoding efficiency for latent video diffusion models.</description><link>https://weedge.us.kg/podcast/688c68ef37fb413b8fba95aa0b362387</link><guid>https://weedge.us.kg/podcast/688c68ef37fb413b8fba95aa0b362387</guid><pubDate>Sun, 15 Dec 2024 19:19:55 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2411.17459v2_2024-12-15_19-17-47.mp3" length="1458573" type="audio/mpeg" /><itunes:duration>06:04</itunes:duration></item><item><title>Open-Sora Plan: 开源大型视频生成模型</title><description>本播客深入探讨了Open-Sora Plan，一个旨在生成高质量、长时视频的开源项目。我们将详细分析其核心模型、辅助策略和数据处理流程。</description><link>https://weedge.us.kg/podcast/cc791dd133da429aabfb87edba45d60e</link><guid>https://weedge.us.kg/podcast/cc791dd133da429aabfb87edba45d60e</guid><pubDate>Sun, 15 Dec 2024 19:32:06 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2412.00131v1_2024-12-15_19-29-42.mp3" length="1532589" type="audio/mpeg" /><itunes:duration>06:23</itunes:duration></item><item><title>ModernBERT: A Deep Dive into Efficient Encoder Models</title><description>An in-depth discussion of the ModernBERT paper, exploring its architecture, training methodology, and performance across various NLP tasks.</description><link>https://weedge.us.kg/podcast/19fe02a01f8d44b1888ce425deea2c7a</link><guid>https://weedge.us.kg/podcast/19fe02a01f8d44b1888ce425deea2c7a</guid><pubDate>Sat, 21 Dec 2024 08:53:16 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2412.13663v2_2024-12-21_08-51-30.mp3" length="1276365" type="audio/mpeg" /><itunes:duration>05:18</itunes:duration></item><item><title>AI前沿：POINTS1.5视觉语言模型深度解析</title><description>本期播客深入探讨了腾讯微信AI团队推出的最新视觉语言模型POINTS1.5，从模型架构、双语支持到训练策略，全面解析其在真实世界应用中的潜力。</description><link>https://weedge.us.kg/podcast/eaa833fc16cc42739f471b029492532b</link><guid>https://weedge.us.kg/podcast/eaa833fc16cc42739f471b029492532b</guid><pubDate>Sat, 21 Dec 2024 12:56:48 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2412.08443v1_2024-12-21_12-54-51.mp3" length="1835277" type="audio/mpeg" /><itunes:duration>07:38</itunes:duration></item><item><title>Byte Latent Transformer: Patches Scale Better Than Tokens</title><description>A podcast discussing the Byte Latent Transformer (BLT), a novel byte-level LLM architecture that matches tokenization-based LLM performance with improvements in inference efficiency and robustness.</description><link>https://weedge.us.kg/podcast/654d705f964d4590b2b596c4c504c2a6</link><guid>https://weedge.us.kg/podcast/654d705f964d4590b2b596c4c504c2a6</guid><pubDate>Sat, 21 Dec 2024 14:42:00 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2412.09871v1_2024-12-21_14-39-33.mp3" length="1346349" type="audio/mpeg" /><itunes:duration>05:36</itunes:duration></item><item><title>PaliGemma 2: A Versatile Vision-Language Model</title><description>A podcast discussion about PaliGemma 2, a family of versatile vision-language models, and its capabilities in various tasks.</description><link>https://weedge.us.kg/podcast/f8ac261fff714411b6e05b203b1cdbd3</link><guid>https://weedge.us.kg/podcast/f8ac261fff714411b6e05b203b1cdbd3</guid><pubDate>Sat, 21 Dec 2024 16:22:51 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2412.03555v1_2024-12-21_16-20-25.mp3" length="1710093" type="audio/mpeg" /><itunes:duration>07:07</itunes:duration></item><item><title>从慢速双向到快速因果视频生成器</title><description>本播客讨论了一种新的视频生成方法，该方法通过将预训练的双向扩散模型转化为因果模型，并结合分布匹配蒸馏技术，实现了快速、高质量的视频生成。该方法支持流式视频生成、视频到视频的转换、图像到视频的生成以及动态提示。</description><link>https://weedge.us.kg/podcast/53477ed6f0da47a68b5588f760db3b61</link><guid>https://weedge.us.kg/podcast/53477ed6f0da47a68b5588f760db3b61</guid><pubDate>Mon, 23 Dec 2024 18:07:16 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2412.07772v1_2024-12-23_18-04-11.mp3" length="1450317" type="audio/mpeg" /><itunes:duration>06:02</itunes:duration></item><item><title>Speech and Language Processing</title><description>A podcast discussing the content from Daniel Jurafsky and James H. Martin&amp;#x27;s &amp;quot;Speech and Language Processing&amp;quot; textbook, Third Edition draft, specifically focusing on fundamental algorithms for NLP, NLP applications, and annotating linguistic structure.</description><link>https://weedge.us.kg/podcast/867aee33c19545078393cfe1b69fe4f4</link><guid>https://weedge.us.kg/podcast/867aee33c19545078393cfe1b69fe4f4</guid><pubDate>Tue, 24 Dec 2024 17:54:02 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/Speech and Language Processing.pdf_2024-12-24_17-49-15.mp3" length="2426253" type="audio/mpeg" /><itunes:duration>10:06</itunes:duration></item><item><title>深入浅出：注意力机制的演变与应用</title><description>本期播客将深入探讨注意力机制在深度学习领域的演变与应用，从Seq2Seq模型的局限性到Transformer的创新，再到Self-Attention GAN的强大功能，我们将一步步揭开注意力机制的神秘面纱，带您领略其在自然语言处理、计算机视觉等领域的卓越表现。</description><link>https://weedge.us.kg/podcast/2819beb579cd4d719d8794aea214bf85</link><guid>https://weedge.us.kg/podcast/2819beb579cd4d719d8794aea214bf85</guid><pubDate>Wed, 25 Dec 2024 13:00:41 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2018-06-24-attention_2024-12-25_12-58-22.mp3" length="1697325" type="audio/mpeg" /><itunes:duration>07:04</itunes:duration></item><item><title>F5-TTS: 突破性文本到语音技术</title><description>深入探讨 F5-TTS，一种基于流匹配的非自回归文本到语音系统，该系统在零样本语音合成方面表现出色。</description><link>https://weedge.us.kg/podcast/c321abc9ebbe42f3a31ed70298d067c5</link><guid>https://weedge.us.kg/podcast/c321abc9ebbe42f3a31ed70298d067c5</guid><pubDate>Fri, 27 Dec 2024 13:00:46 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2410.06885v2_2024-12-27_12-58-45.mp3" length="1368621" type="audio/mpeg" /><itunes:duration>05:42</itunes:duration></item><item><title>BigVGAN: 通用神经声码器大规模训练</title><description>本播客讨论了BigVGAN，一种通用的神经声码器，它通过大规模训练实现高保真音频合成，并在各种分布外场景中表现出色。</description><link>https://weedge.us.kg/podcast/83298f133a944c7e964d08c261c6cf96</link><guid>https://weedge.us.kg/podcast/83298f133a944c7e964d08c261c6cf96</guid><pubDate>Fri, 27 Dec 2024 13:25:33 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2206.04658_2024-12-27_13-23-12.mp3" length="1212621" type="audio/mpeg" /><itunes:duration>05:03</itunes:duration></item><item><title>E2 TTS: 令人惊讶的简单零样本文本到语音技术</title><description>本期节目深入探讨了E2 TTS，一种完全非自回归的零样本文本到语音系统，它在自然度、说话人相似度和可懂度方面都达到了最先进的水平。我们将详细讨论其训练过程、推理方法以及如何通过其扩展来提升用户体验。</description><link>https://weedge.us.kg/podcast/0e5a7f969dfa41d88de38b96ad4cb18a</link><guid>https://weedge.us.kg/podcast/0e5a7f969dfa41d88de38b96ad4cb18a</guid><pubDate>Fri, 27 Dec 2024 13:40:44 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2406.18009v2_2024-12-27_13-37-57.mp3" length="1803789" type="audio/mpeg" /><itunes:duration>07:30</itunes:duration></item><item><title>DeepSeek-V3: A Deep Dive into a Powerful Mixture-of-Experts Model</title><description>A podcast discussion analyzing the DeepSeek-V3 technical report, covering its architecture, training, and performance.</description><link>https://weedge.us.kg/podcast/497b358255124fb693059b419d50418e</link><guid>https://weedge.us.kg/podcast/497b358255124fb693059b419d50418e</guid><pubDate>Fri, 27 Dec 2024 17:02:55 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/DeepSeek_V3.pdf_2024-12-27_17-00-25.mp3" length="1345581" type="audio/mpeg" /><itunes:duration>05:36</itunes:duration></item><item><title>DeepSeekMoE: 超越专家混合模型的终极专业化</title><description>本期播客深入探讨了DeepSeekMoE这一创新的混合专家模型架构，旨在实现专家知识的终极专业化。我们将讨论其核心策略、实验验证以及与现有模型的对比，揭示其在大型语言模型领域的优势。</description><link>https://weedge.us.kg/podcast/2b69c951bda24d6fb67db6545db5063e</link><guid>https://weedge.us.kg/podcast/2b69c951bda24d6fb67db6545db5063e</guid><pubDate>Sat, 28 Dec 2024 22:14:01 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2401.06066_2024-12-28_22-10-22.mp3" length="1602381" type="audio/mpeg" /><itunes:duration>06:40</itunes:duration></item><item><title>InternLM-XComposer2.5-OmniLive: A Comprehensive Multimodal System</title><description>A podcast discussing the InternLM-XComposer2.5-OmniLive system, a novel multimodal AI for long-term video and audio interaction.</description><link>https://weedge.us.kg/podcast/d2ca663028f24728b9713064e72c5799</link><guid>https://weedge.us.kg/podcast/d2ca663028f24728b9713064e72c5799</guid><pubDate>Thu, 02 Jan 2025 09:26:55 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2412.09596v1_2025-01-02_09-25-10.mp3" length="1552557" type="audio/mpeg" /><itunes:duration>06:28</itunes:duration></item><item><title>AI Radio FM - Technology Channel</title><description>A podcast discussing InternLM-XComposer-2.5, a versatile large vision language model.</description><link>https://weedge.us.kg/podcast/8653f011f6a245d5b0cab09f1b65ed18</link><guid>https://weedge.us.kg/podcast/8653f011f6a245d5b0cab09f1b65ed18</guid><pubDate>Thu, 02 Jan 2025 09:40:08 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2407.03320v1_2025-01-02_09-37-51.mp3" length="1463565" type="audio/mpeg" /><itunes:duration>06:05</itunes:duration></item><item><title>AI Radio FM - Technology Channel, Your Personal Generative AI Podcast</title><description>A fast-paced, enthusiastic podcast discussing the latest advancements in AI, focusing on the InternLM-XComposer2-4KHD model.</description><link>https://weedge.us.kg/podcast/cd94006a4bc041dba68719e951e20f0a</link><guid>https://weedge.us.kg/podcast/cd94006a4bc041dba68719e951e20f0a</guid><pubDate>Thu, 02 Jan 2025 09:44:30 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2404.06512v1_2025-01-02_09-42-19.mp3" length="1556109" type="audio/mpeg" /><itunes:duration>06:28</itunes:duration></item><item><title>AI Radio FM - Technology Channel, Your Personal Generative AI Podcast</title><description>A podcast discussing the InternLM-XComposer2 model, its architecture, and capabilities in free-form text-image composition and comprehension.</description><link>https://weedge.us.kg/podcast/dbb70cdb985644a0ba47853576a2f303</link><guid>https://weedge.us.kg/podcast/dbb70cdb985644a0ba47853576a2f303</guid><pubDate>Thu, 02 Jan 2025 10:15:33 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2401.16420_2025-01-02_10-13-07.mp3" length="1811949" type="audio/mpeg" /><itunes:duration>07:32</itunes:duration></item><item><title>Mooncake：一种以KVCache为中心的LLM服务解耦架构</title><description>本播客深入探讨Mooncake的创新架构，这是一种专为高效服务大型语言模型而设计的解耦系统。</description><link>https://weedge.us.kg/podcast/41ecc58fe000404d8a0f93851bea9f52</link><guid>https://weedge.us.kg/podcast/41ecc58fe000404d8a0f93851bea9f52</guid><pubDate>Sat, 04 Jan 2025 11:23:47 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2407.00079v3_2025-01-04_11-21-53.mp3" length="1332813" type="audio/mpeg" /><itunes:duration>05:33</itunes:duration></item><item><title>LLM推理优化：连续批处理实现23倍吞吐量提升</title><description>本期播客深入探讨了大型语言模型（LLM）推理中的连续批处理技术，揭示了其如何显著提高吞吐量并降低延迟。我们将讨论传统批处理的局限性，并详细介绍连续批处理的原理及其在实际应用中的优势，尤其是在使用vLLM时的卓越性能表现。</description><link>https://weedge.us.kg/podcast/3c0fe7f9b5274e7db3b5db5faa475e36</link><guid>https://weedge.us.kg/podcast/3c0fe7f9b5274e7db3b5db5faa475e36</guid><pubDate>Sat, 04 Jan 2025 11:40:01 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/continuous-batching-llm-inference_2025-01-04_11-37-53.mp3" length="1458093" type="audio/mpeg" /><itunes:duration>06:04</itunes:duration></item><item><title>ORCA: 分布式Transformer生成模型服务系统</title><description>本期播客深入探讨了ORCA，一个为Transformer模型设计的分布式服务系统。我们将详细介绍其创新的迭代级调度和选择性批处理技术，以及它们如何显著提升模型服务的性能。</description><link>https://weedge.us.kg/podcast/00ec8aa602e8471d9e7220b190c529ab</link><guid>https://weedge.us.kg/podcast/00ec8aa602e8471d9e7220b190c529ab</guid><pubDate>Sat, 04 Jan 2025 12:05:55 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/Orca- A Distributed Serving System for Transformer-Based Generative Models.pdf_2025-01-04_12-03-45.mp3" length="1363149" type="audio/mpeg" /><itunes:duration>05:40</itunes:duration></item><item><title>AI Radio FM - Technology Channel: PagedAttention for Large Language Model Serving</title><description>A podcast discussing PagedAttention, a novel memory management technique for serving large language models, and its implementation in vLLM.</description><link>https://weedge.us.kg/podcast/f8d0faea7b504430afefb761af7821ac</link><guid>https://weedge.us.kg/podcast/f8d0faea7b504430afefb761af7821ac</guid><pubDate>Sat, 04 Jan 2025 12:48:33 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2309.06180_2025-01-04_12-45-48.mp3" length="1805133" type="audio/mpeg" /><itunes:duration>07:31</itunes:duration></item><item><title>AI驱动的大规模语言模型训练：Megatron-LM在GPU集群上的高效实践</title><description>本期播客深入探讨了如何使用Megatron-LM在GPU集群上高效训练大规模语言模型，重点关注张量并行、流水线并行和数据并行的组合应用，以及创新的交错流水线调度方法。</description><link>https://weedge.us.kg/podcast/a95ae8ce47d24376b8a165e633b7abaa</link><guid>https://weedge.us.kg/podcast/a95ae8ce47d24376b8a165e633b7abaa</guid><pubDate>Sat, 04 Jan 2025 13:06:15 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2104.04473_2025-01-04_13-04-07.mp3" length="1725645" type="audio/mpeg" /><itunes:duration>07:11</itunes:duration></item><item><title>序列并行：从系统角度进行长序列训练</title><description>探讨一种名为“序列并行”的内存高效并行方法，该方法旨在突破输入序列长度的限制，并能在GPU上高效训练更长的序列。该方法与现有的并行技术兼容，并能实现4D并行。核心思想是将输入序列分割成多个块，并分配给不同的GPU进行处理。为了计算注意力输出，引入了环形自注意力机制。</description><link>https://weedge.us.kg/podcast/07783b05ecf640ce95e495a0f9b0195e</link><guid>https://weedge.us.kg/podcast/07783b05ecf640ce95e495a0f9b0195e</guid><pubDate>Sat, 04 Jan 2025 13:14:33 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2105.13120_2025-01-04_13-12-20.mp3" length="1294797" type="audio/mpeg" /><itunes:duration>05:23</itunes:duration></item><item><title>大型Transformer模型中减少激活重计算</title><description>本播客讨论了一种加速大型Transformer模型训练的新方法，通过减少激活重计算来实现。我们将深入探讨序列并行和选择性激活重计算技术。</description><link>https://weedge.us.kg/podcast/d4ce1326df1849bca2dbe174b94753ed</link><guid>https://weedge.us.kg/podcast/d4ce1326df1849bca2dbe174b94753ed</guid><pubDate>Sat, 04 Jan 2025 13:18:12 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2205.05198_2025-01-04_13-15-47.mp3" length="1461165" type="audio/mpeg" /><itunes:duration>06:05</itunes:duration></item><item><title>DistFlashAttn: 分布式长文本大语言模型训练的内存高效注意力机制</title><description>本播客深入探讨 DistFlashAttn，一种专为长文本大语言模型训练设计的分布式内存高效注意力机制，详细解析其核心技术和性能优势。</description><link>https://weedge.us.kg/podcast/4c93f04f3d1645669a6ce6fd5022d47b</link><guid>https://weedge.us.kg/podcast/4c93f04f3d1645669a6ce6fd5022d47b</guid><pubDate>Sat, 04 Jan 2025 13:20:26 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2310.03294_2025-01-04_13-18-32.mp3" length="1654797" type="audio/mpeg" /><itunes:duration>06:53</itunes:duration></item><item><title>DeepSpeed Ulysses: 极端长序列Transformer模型训练的系统优化</title><description>本播客深入探讨了DeepSpeed Ulysses，一种用于训练具有极长序列长度的Transformer模型的创新方法，它通过优化序列并行性和通信效率，显著提升了训练速度和可扩展性。我们将讨论其核心设计、通信分析、内存效率以及与现有方法的比较。</description><link>https://weedge.us.kg/podcast/4cf804a69dd8454884da01b2f75038f8</link><guid>https://weedge.us.kg/podcast/4cf804a69dd8454884da01b2f75038f8</guid><pubDate>Sat, 04 Jan 2025 13:23:54 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2309.14509_2025-01-04_13-21-35.mp3" length="1751565" type="audio/mpeg" /><itunes:duration>07:17</itunes:duration></item><item><title>FlashAttention: 高效且内存优化的精确注意力机制</title><description>探讨 FlashAttention 算法，一种在 GPU 上实现快速、内存高效精确注意力机制的新方法。深入分析其 IO 复杂度，并与现有的注意力机制进行性能比较。</description><link>https://weedge.us.kg/podcast/4b0bfa35ed664186b2d3ab5519d9fc81</link><guid>https://weedge.us.kg/podcast/4b0bfa35ed664186b2d3ab5519d9fc81</guid><pubDate>Sat, 04 Jan 2025 13:29:59 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2205.14135_2025-01-04_13-27-52.mp3" length="1702989" type="audio/mpeg" /><itunes:duration>07:05</itunes:duration></item><item><title>AI FlashAttention-2 Podcast</title><description>A fast-paced discussion on FlashAttention-2, a faster attention mechanism for Transformers, exploring its algorithms, parallelism, and performance benefits.</description><link>https://weedge.us.kg/podcast/4cbb841c7012452e8b83aee61c4fbb58</link><guid>https://weedge.us.kg/podcast/4cbb841c7012452e8b83aee61c4fbb58</guid><pubDate>Sat, 04 Jan 2025 13:33:03 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2307.08691_2025-01-04_13-30-37.mp3" length="1509165" type="audio/mpeg" /><itunes:duration>06:17</itunes:duration></item><item><title>FlashAttention-3: Revolutionizing Attention Mechanisms on GPUs</title><description>A podcast discussing the FlashAttention-3 algorithm, its improvements over previous versions, and its impact on large language models.</description><link>https://weedge.us.kg/podcast/79dcda0a7cb8482ead5ab5438c648147</link><guid>https://weedge.us.kg/podcast/79dcda0a7cb8482ead5ab5438c648147</guid><pubDate>Sat, 04 Jan 2025 13:35:47 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2407.08608_2025-01-04_13-33-42.mp3" length="1101549" type="audio/mpeg" /><itunes:duration>04:35</itunes:duration></item><item><title>Ring Attention with Blockwise Transformers for Near-Infinite Context</title><description>A podcast discussing a novel approach to scale transformer models to handle near-infinite context lengths.</description><link>https://weedge.us.kg/podcast/d05e9b653db848b6835671ccf52733ed</link><guid>https://weedge.us.kg/podcast/d05e9b653db848b6835671ccf52733ed</guid><pubDate>Sat, 04 Jan 2025 13:43:23 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2310.01889_2025-01-04_13-40-57.mp3" length="1526541" type="audio/mpeg" /><itunes:duration>06:21</itunes:duration></item><item><title>LoongTrain: 高效长序列大语言模型训练</title><description>本期播客深入探讨LoongTrain，一个为长序列大语言模型设计的高效训练框架。我们将讨论其核心的2D注意力机制，以及它如何结合头并行和上下文并行来克服扩展性限制并保持效率。此外，还将分析Double-Ring-Attention机制，以及设备放置策略对训练速度的影响。</description><link>https://weedge.us.kg/podcast/63f73b702324420caae3eecf36ed5540</link><guid>https://weedge.us.kg/podcast/63f73b702324420caae3eecf36ed5540</guid><pubDate>Sat, 04 Jan 2025 13:50:28 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2406.18485_2025-01-04_13-47-18.mp3" length="1810125" type="audio/mpeg" /><itunes:duration>07:32</itunes:duration></item><item><title>统一序列并行方法：为长上下文生成式AI赋能</title><description>本播客深入探讨了统一序列并行（Unified Sequence Parallelism，简称USP）方法，这是一种用于训练具有极长上下文的生成式AI模型的先进技术。我们分析了现有的序列并行方法，如DeepSpeed-Ulysses和Ring-Attention，并提出了一个统一的框架，该框架结合了两者的优点，同时克服了它们的局限性。通过详细讨论，我们将深入了解USP如何与数据并行、张量并行、ZeRO和流水线并行等现有并行技术相结合，从而为4D混合并行系统提供最佳实践。此外，我们还分享了实验结果，这些结果强调了USP在各种硬件配置下的性能，并展示了其在扩展模型上下文长度和提高训练效率方面的潜力。</description><link>https://weedge.us.kg/podcast/c4827b8419e84cd4beec19bf928214fc</link><guid>https://weedge.us.kg/podcast/c4827b8419e84cd4beec19bf928214fc</guid><pubDate>Sat, 04 Jan 2025 13:56:07 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2405.07719_2025-01-04_13-53-53.mp3" length="1745037" type="audio/mpeg" /><itunes:duration>07:16</itunes:duration></item><item><title>混合张量专家数据并行方法优化混合专家训练</title><description>深入探讨 DeepSpeed-TED，一种新颖的三维混合并行框架，用于训练具有大型基础模型的混合专家模型。我们讨论了内存优化、通信优化以及与现有方法的性能比较。</description><link>https://weedge.us.kg/podcast/79672084c92546caaae7588fec3ed7a0</link><guid>https://weedge.us.kg/podcast/79672084c92546caaae7588fec3ed7a0</guid><pubDate>Sat, 04 Jan 2025 14:31:17 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2303.06318_2025-01-04_14-29-13.mp3" length="1279917" type="audio/mpeg" /><itunes:duration>05:19</itunes:duration></item><item><title>AI Radio FM - Technology Channel: GShard and Giant Models</title><description>A deep dive into GShard, a module for scaling giant neural networks, focusing on its application to multilingual machine translation and its impact on training efficiency and model quality.</description><link>https://weedge.us.kg/podcast/36d2d61d10d744809efab89bf0ae2e79</link><guid>https://weedge.us.kg/podcast/36d2d61d10d744809efab89bf0ae2e79</guid><pubDate>Sat, 04 Jan 2025 14:42:37 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2006.16668_2025-01-04_14-40-02.mp3" length="2076045" type="audio/mpeg" /><itunes:duration>08:38</itunes:duration></item><item><title>GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding</title><description>A podcast discussion about GShard, a module for scaling neural networks using conditional computation and automatic sharding, focusing on its application to multilingual machine translation.</description><link>https://weedge.us.kg/podcast/eb37f53b503b4bf8b4513afce70d39c8</link><guid>https://weedge.us.kg/podcast/eb37f53b503b4bf8b4513afce70d39c8</guid><pubDate>Sat, 04 Jan 2025 14:48:41 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2006.16668_2025-01-04_14-46-24.mp3" length="1477005" type="audio/mpeg" /><itunes:duration>06:09</itunes:duration></item><item><title>零气泡流水线并行</title><description>本期播客深入探讨了零气泡流水线并行技术，这是一种旨在提高大规模分布式训练效率的创新方法。我们分析了传统流水线并行方法中的气泡问题，并介绍了如何通过精细化调度和优化器同步绕过技术来实现零气泡。此外，我们还讨论了自动调度算法、内存优化策略以及实验结果，旨在为听众提供一个全面而深入的技术解析。</description><link>https://weedge.us.kg/podcast/51712154b34b407c80ea67c165e43926</link><guid>https://weedge.us.kg/podcast/51712154b34b407c80ea67c165e43926</guid><pubDate>Sat, 04 Jan 2025 14:53:56 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2401.10241_2025-01-04_14-51-47.mp3" length="1577229" type="audio/mpeg" /><itunes:duration>06:34</itunes:duration></item><item><title>混合专家模型（MoE）技术综述</title><description>本播客深入探讨了混合专家模型（MoE）的最新进展、算法设计、系统实现以及实际应用。从稀疏和密集MoE的背景知识开始，我们提出了一个创新的MoE分类法，并探讨了选通函数、专家网络、训练方案和系统设计方面的复杂性，从而全面了解MoE。</description><link>https://weedge.us.kg/podcast/8a289301496246d295e9f3453b7e1f0a</link><guid>https://weedge.us.kg/podcast/8a289301496246d295e9f3453b7e1f0a</guid><pubDate>Sat, 04 Jan 2025 14:56:44 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2407.06204v2_2025-01-04_14-54-20.mp3" length="1287117" type="audio/mpeg" /><itunes:duration>05:21</itunes:duration></item><item><title>AI Radio FM - Technology Channel, Your Personal Generative AI Podcast</title><description>A podcast discussing the auxiliary-loss-free load balancing strategy for mixture-of-experts models.</description><link>https://weedge.us.kg/podcast/9cd7a513964d4dd799d8ef7ad0c5579a</link><guid>https://weedge.us.kg/podcast/9cd7a513964d4dd799d8ef7ad0c5579a</guid><pubDate>Sat, 04 Jan 2025 19:56:48 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2408.15664_2025-01-04_19-54-57.mp3" length="1300269" type="audio/mpeg" /><itunes:duration>05:24</itunes:duration></item><item><title>AI Vision Podcast: Masked Autoencoders for Scalable Vision Learning</title><description>A deep dive into Masked Autoencoders (MAE) and their impact on computer vision, discussing their architecture, training efficiency, and performance on ImageNet and downstream tasks.</description><link>https://weedge.us.kg/podcast/850c72ae38f341579cbc3813ffff1fef</link><guid>https://weedge.us.kg/podcast/850c72ae38f341579cbc3813ffff1fef</guid><pubDate>Sun, 05 Jan 2025 18:09:30 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2111.06377_2025-01-05_18-07-43.mp3" length="1303629" type="audio/mpeg" /><itunes:duration>05:25</itunes:duration></item><item><title>ConvNeXt: A Modern ConvNet for the 2020s</title><description>A podcast discussing the architecture and performance of ConvNeXt, a modern ConvNet model that challenges the dominance of Vision Transformers.</description><link>https://weedge.us.kg/podcast/d1ed2bbef5b34ccb8fd28ddf4b651174</link><guid>https://weedge.us.kg/podcast/d1ed2bbef5b34ccb8fd28ddf4b651174</guid><pubDate>Sun, 05 Jan 2025 18:14:28 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2201.03545_2025-01-05_18-12-02.mp3" length="1555821" type="audio/mpeg" /><itunes:duration>06:28</itunes:duration></item><item><title>Swin Transformer: A New Vision Transformer</title><description>A podcast discussing the Swin Transformer, a hierarchical vision transformer using shifted windows for computer vision tasks.</description><link>https://weedge.us.kg/podcast/4f3c971a44fe4cd7901e3039f13cf01c</link><guid>https://weedge.us.kg/podcast/4f3c971a44fe4cd7901e3039f13cf01c</guid><pubDate>Sun, 05 Jan 2025 18:59:20 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2103.14030_2025-01-05_18-57-02.mp3" length="1850157" type="audio/mpeg" /><itunes:duration>07:42</itunes:duration></item><item><title>Flow Matching for Generative Modeling</title><description>A podcast discussing the new paradigm for generative modeling using Continuous Normalizing Flows (CNFs) called Flow Matching (FM). FM offers a simulation-free approach for training CNFs by regressing vector fields of fixed conditional probability paths, which enables training CNFs at unprecedented scale and allows for the use of different probability paths.</description><link>https://weedge.us.kg/podcast/ca7fae86dcc44ef39152b1c0fc92a089</link><guid>https://weedge.us.kg/podcast/ca7fae86dcc44ef39152b1c0fc92a089</guid><pubDate>Mon, 06 Jan 2025 10:50:53 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2210.02747_2025-01-06_10-48-48.mp3" length="1454157" type="audio/mpeg" /><itunes:duration>06:03</itunes:duration></item><item><title>CosyVoice 2: 使用大型语言模型实现可扩展的流式语音合成</title><description>一个关于 CosyVoice 2 的播客，这是一个改进的流式语音合成模型，它利用大型语言模型，实现了接近人类水平的自然度，最小的响应延迟，以及在流模式下几乎无损的合成质量。</description><link>https://weedge.us.kg/podcast/a5144dc473e64888a7cb4e04ceec32fa</link><guid>https://weedge.us.kg/podcast/a5144dc473e64888a7cb4e04ceec32fa</guid><pubDate>Mon, 06 Jan 2025 10:56:09 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2412.10117_2025-01-06_10-53-27.mp3" length="1925901" type="audio/mpeg" /><itunes:duration>08:01</itunes:duration></item><item><title>AI驱动的交互式头部生成</title><description>本期播客深入探讨了INFP，一个用于双人对话的音频驱动的头部生成框架。我们将探讨其创新方法、数据集以及实验结果，展示其在自然人机交互中的潜力。</description><link>https://weedge.us.kg/podcast/cd8d0aca47e140fc96e5e27876dc2363</link><guid>https://weedge.us.kg/podcast/cd8d0aca47e140fc96e5e27876dc2363</guid><pubDate>Mon, 06 Jan 2025 14:24:22 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2412.04037_2025-01-06_14-22-22.mp3" length="1324365" type="audio/mpeg" /><itunes:duration>05:30</itunes:duration></item><item><title>Infinity: Scaling Bitwise Autoregressive Modeling for High-Resolution Image Synthesis</title><description>A podcast discussing the groundbreaking research paper on Infinity, a novel autoregressive model for high-resolution image synthesis.</description><link>https://weedge.us.kg/podcast/f606a111b80c43789445d63b78fe3b8c</link><guid>https://weedge.us.kg/podcast/f606a111b80c43789445d63b78fe3b8c</guid><pubDate>Mon, 06 Jan 2025 14:29:59 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2412.04431_2025-01-06_14-27-46.mp3" length="1491693" type="audio/mpeg" /><itunes:duration>06:12</itunes:duration></item><item><title>LatentSync: Audio Conditioned Latent Diffusion Models for Lip Sync</title><description>A deep dive into LatentSync, an innovative lip-sync framework using audio-conditioned latent diffusion models, its methodology, experiments, and the resolution of SyncNet convergence issues.</description><link>https://weedge.us.kg/podcast/d7cba4be428440fcb7ea18ce7a3133cb</link><guid>https://weedge.us.kg/podcast/d7cba4be428440fcb7ea18ce7a3133cb</guid><pubDate>Mon, 06 Jan 2025 20:32:37 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2412.09262_2025-01-06_20-29-29.mp3" length="2236653" type="audio/mpeg" /><itunes:duration>09:19</itunes:duration></item><item><title>PowerInfer-2: Fast Large Language Model Inference on a Smartphone</title><description>A podcast discussion about PowerInfer-2, a framework for running large language models on smartphones, focusing on its neuron cluster design, adaptive computation strategies, and I/O optimizations.</description><link>https://weedge.us.kg/podcast/c73b8ca57cb249b2b1ea4648f4b967a6</link><guid>https://weedge.us.kg/podcast/c73b8ca57cb249b2b1ea4648f4b967a6</guid><pubDate>Tue, 07 Jan 2025 14:44:00 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2406.06282_2025-01-07_14-40-53.mp3" length="2894733" type="audio/mpeg" /><itunes:duration>12:03</itunes:duration></item><item><title>AI科技前沿：故事扩散模型深度解析</title><description>本期播客深入探讨故事扩散模型，一种用于生成连贯图像和视频的新方法。我们将详细分析其核心技术，包括一致性自注意力机制和语义运动预测器，并讨论其在视觉故事生成方面的应用和潜力。</description><link>https://weedge.us.kg/podcast/01a06db1be7246faa6b137b3a7d803a1</link><guid>https://weedge.us.kg/podcast/01a06db1be7246faa6b137b3a7d803a1</guid><pubDate>Tue, 07 Jan 2025 16:19:41 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2405.01434_2025-01-07_16-17-01.mp3" length="2234253" type="audio/mpeg" /><itunes:duration>09:18</itunes:duration></item><item><title>AI Radio FM - Technology Channel, Your Personal Generative AI Podcast</title><description>A podcast discussing the Story-Adapter framework for long story visualization.</description><link>https://weedge.us.kg/podcast/ecaa886c7f294e9ea8947c8b55b37c81</link><guid>https://weedge.us.kg/podcast/ecaa886c7f294e9ea8947c8b55b37c81</guid><pubDate>Tue, 07 Jan 2025 16:22:19 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2410.06244_2025-01-07_16-20-12.mp3" length="1136301" type="audio/mpeg" /><itunes:duration>04:43</itunes:duration></item><item><title>智能格林：基于潜在扩散模型的开放式视觉故事讲述</title><description>本期播客讨论了一篇关于使用潜在扩散模型进行开放式视觉故事讲述的论文。我们深入探讨了该模型的技术细节、数据集构建以及实验结果，展示了其在生成连贯图像序列方面的卓越能力。</description><link>https://weedge.us.kg/podcast/cfa03464b3374d2fb69c65f0ab6f604f</link><guid>https://weedge.us.kg/podcast/cfa03464b3374d2fb69c65f0ab6f604f</guid><pubDate>Tue, 07 Jan 2025 16:11:06 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2306.00973_2025-01-07_16-44-52.mp3" length="1747341" type="audio/mpeg" /><itunes:duration>07:16</itunes:duration></item><item><title>AI Radio FM - Technology Channel</title><description>A podcast discussing the IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models</description><link>https://weedge.us.kg/podcast/3af628c338144cebae2db524de93aacf</link><guid>https://weedge.us.kg/podcast/3af628c338144cebae2db524de93aacf</guid><pubDate>Tue, 07 Jan 2025 16:00:21 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2308.06721_2025-01-07_16-47-28.mp3" length="1899117" type="audio/mpeg" /><itunes:duration>07:54</itunes:duration></item><item><title>宇宙世界基础模型平台：物理人工智能的未来</title><description>深入探讨NVIDIA Cosmos世界基础模型平台，该平台旨在促进物理人工智能的发展，通过数字孪生和世界模型，加速人工智能在现实世界中的应用。</description><link>https://weedge.us.kg/podcast/606d5ac99e524cd7856f6943dc13e5d3</link><guid>https://weedge.us.kg/podcast/606d5ac99e524cd7856f6943dc13e5d3</guid><pubDate>Tue, 07 Jan 2025 21:08:55 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/NVIDIA Cosmos_2.pdf_2025-01-07_21-00-03.mp3" length="1547565" type="audio/mpeg" /><itunes:duration>06:26</itunes:duration></item><item><title>WavChat：语音对话模型调查</title><description>本播客深入探讨了语音对话模型的最新进展，包括其功能、表示形式、训练范式以及流媒体和交互能力。</description><link>https://weedge.us.kg/podcast/f738f00836c944fabfe0c39d531f6e3d</link><guid>https://weedge.us.kg/podcast/f738f00836c944fabfe0c39d531f6e3d</guid><pubDate>Thu, 09 Jan 2025 10:03:13 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2411.13577_2025-01-09_09-59-15.mp3" length="3281229" type="audio/mpeg" /><itunes:duration>13:40</itunes:duration></item><item><title>StyleTTS 2: Towards Human-Level Text-to-Speech</title><description>A podcast discussion about the StyleTTS 2 model for text-to-speech synthesis, focusing on its innovative use of style diffusion and adversarial training with large speech language models to achieve human-level performance.</description><link>https://weedge.us.kg/podcast/dfac57a4418f499284571b4602efeb78</link><guid>https://weedge.us.kg/podcast/dfac57a4418f499284571b4602efeb78</guid><pubDate>Thu, 09 Jan 2025 11:07:02 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2306.07691_2025-01-09_11-05-05.mp3" length="1505613" type="audio/mpeg" /><itunes:duration>06:16</itunes:duration></item><item><title>AI技术前沿：Phi-4 大型语言模型的突破</title><description>深入探讨微软最新发布的Phi-4大型语言模型，了解其在数据质量、合成数据、训练方法和后训练优化方面的创新。 我们将分析其在各种基准测试上的表现，以及它如何超越以往的Phi系列模型，甚至在某些领域超越更大的模型。</description><link>https://weedge.us.kg/podcast/e1c7c7fdfadb4ff6a5bee06b91df76cf</link><guid>https://weedge.us.kg/podcast/e1c7c7fdfadb4ff6a5bee06b91df76cf</guid><pubDate>Thu, 09 Jan 2025 11:51:19 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/phi4.pdf_2025-01-09_11-47-15.mp3" length="1952973" type="audio/mpeg" /><itunes:duration>08:08</itunes:duration></item><item><title>iSTFTNet: 快速轻量级梅尔频谱声码器</title><description>探讨iSTFTNet如何通过逆短时傅里叶变换优化梅尔频谱声码器，提高速度和效率。</description><link>https://weedge.us.kg/podcast/c2b7b9285d9d4daeadfb8e06f8f10b54</link><guid>https://weedge.us.kg/podcast/c2b7b9285d9d4daeadfb8e06f8f10b54</guid><pubDate>Thu, 09 Jan 2025 18:02:28 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2203.02395_2025-01-09_18-00-15.mp3" length="1278093" type="audio/mpeg" /><itunes:duration>05:19</itunes:duration></item><item><title>AI Radio FM - Technology Channel, Your Personal Generative AI Podcast</title><description>A podcast discussing the paper Titans: Learning to Memorize at Test Time.</description><link>https://weedge.us.kg/podcast/8f6e9476ce354674ad0911548d6a7dba</link><guid>https://weedge.us.kg/podcast/8f6e9476ce354674ad0911548d6a7dba</guid><pubDate>Wed, 15 Jan 2025 00:27:15 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2501.00663_2025-01-15_00-23-11.mp3" length="1339725" type="audio/mpeg" /><itunes:duration>05:34</itunes:duration></item><item><title>MinMo：多模态大型语言模型，实现无缝语音交互</title><description>本播客深入探讨了阿里巴巴 Tongyi Lab 的 MinMo 模型，这是一种旨在实现无缝语音交互的多模态大型语言模型。我们讨论了其架构、训练过程以及在各种语音任务中的性能，包括语音识别、翻译、情感识别和全双工对话。</description><link>https://weedge.us.kg/podcast/12b0ecb2c70744b787741312b6dd5e0c</link><guid>https://weedge.us.kg/podcast/12b0ecb2c70744b787741312b6dd5e0c</guid><pubDate>Wed, 15 Jan 2025 10:39:17 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2501.06282v1_2025-01-15_10-35-52.mp3" length="1879437" type="audio/mpeg" /><itunes:duration>07:49</itunes:duration></item><item><title>AI Radio FM - Technology Channel, Your Personal Generative AI Podcast</title><description>A podcast discussing Classifier-Free Diffusion Guidance, a method for improving sample quality in diffusion models without relying on a separate classifier.</description><link>https://weedge.us.kg/podcast/cab1bcd2e0c14f06ab3213889f1c4ba9</link><guid>https://weedge.us.kg/podcast/cab1bcd2e0c14f06ab3213889f1c4ba9</guid><pubDate>Thu, 16 Jan 2025 12:28:18 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2207.12598_2025-01-16_12-24-31.mp3" length="1709133" type="audio/mpeg" /><itunes:duration>07:07</itunes:duration></item><item><title>AI Radio FM - Technology Channel</title><description>A podcast discussing Tensor Product Attention, a novel attention mechanism for Large Language Models.</description><link>https://weedge.us.kg/podcast/7dbd6825c2cc4a259e20376ff7d10ac7</link><guid>https://weedge.us.kg/podcast/7dbd6825c2cc4a259e20376ff7d10ac7</guid><pubDate>Sat, 18 Jan 2025 01:11:19 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2501.06425_2025-01-18_01-08-52.mp3" length="1393677" type="audio/mpeg" /><itunes:duration>05:48</itunes:duration></item><item><title>AI Radio FM - Technology Channel, Your Personal Generative AI Podcast</title><description>A podcast discussing Titans: Learning to Memorize at Test Time.</description><link>https://weedge.us.kg/podcast/b5c8a63dc9b348238503c4005ff135fc</link><guid>https://weedge.us.kg/podcast/b5c8a63dc9b348238503c4005ff135fc</guid><pubDate>Sat, 18 Jan 2025 16:49:32 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2501.00663_2025-01-18_16-45-28.mp3" length="1550061" type="audio/mpeg" /><itunes:duration>06:27</itunes:duration></item><item><title>Sonic: Shifting Focus to Global Audio Perception in Portrait Animation</title><description>A podcast discussing a new approach to audio-driven portrait animation called Sonic, focusing on global audio perception rather than visual cues. The discussion covers the methodology behind Sonic, including context-enhanced audio learning, motion-decoupled controllers, and time-aware position shift fusion, as well as experimental results.</description><link>https://weedge.us.kg/podcast/67a00d4116f9445c86d9b50b193a7bcc</link><guid>https://weedge.us.kg/podcast/67a00d4116f9445c86d9b50b193a7bcc</guid><pubDate>Sun, 19 Jan 2025 00:26:45 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2411.16331_2025-01-19_00-23-30.mp3" length="1443213" type="audio/mpeg" /><itunes:duration>06:00</itunes:duration></item><item><title>AI Radio FM - Technology Channel, Your Personal Generative AI Podcast</title><description>A podcast discussing the research paper &amp;#x27;Addressing Representation Collapse in Vector Quantized Models with One Linear Layer&amp;#x27;</description><link>https://weedge.us.kg/podcast/c112fa1e8d36452b8e8336dc6ef04a65</link><guid>https://weedge.us.kg/podcast/c112fa1e8d36452b8e8336dc6ef04a65</guid><pubDate>Sun, 19 Jan 2025 23:42:37 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2411.02038_2025-01-19_23-39-18.mp3" length="1369485" type="audio/mpeg" /><itunes:duration>05:42</itunes:duration></item><item><title>大规模Transformer模型推理的效率优化</title><description>本播客深入探讨了如何高效地部署大型Transformer模型进行生成式推理，特别是在延迟敏感和长序列长度的场景下。我们将讨论模型并行策略、内存优化和低级优化技术，这些技术共同实现了在延迟和模型FLOPS利用率方面的新的帕累托前沿。</description><link>https://weedge.us.kg/podcast/7144250f2e884897ac84d94d9a1639ad</link><guid>https://weedge.us.kg/podcast/7144250f2e884897ac84d94d9a1639ad</guid><pubDate>Mon, 20 Jan 2025 21:44:07 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2211.05102_2025-01-20_21-41-22.mp3" length="1709133" type="audio/mpeg" /><itunes:duration>07:07</itunes:duration></item><item><title>DistServe：面向高吞吐量的大型语言模型服务的分离式预填充和解码</title><description>本播客讨论了DistServe，一种通过分离预填充和解码计算来提高大型语言模型（LLM）服务性能的系统。我们深入探讨了LLM推理的复杂性，并探讨了DistServe如何克服现有系统的局限性，从而在严格的延迟限制下显著提高服务性能。</description><link>https://weedge.us.kg/podcast/4515989df49a4fe68e43b4f5de17474f</link><guid>https://weedge.us.kg/podcast/4515989df49a4fe68e43b4f5de17474f</guid><pubDate>Thu, 23 Jan 2025 12:20:32 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2401.09670_2025-01-23_12-18-41.mp3" length="1168941" type="audio/mpeg" /><itunes:duration>04:52</itunes:duration></item><item><title>DeepSeek-R1：通过强化学习激励大型语言模型的推理能力</title><description>本播客深入探讨DeepSeek-R1模型，该模型通过大规模强化学习显著提升了大型语言模型的推理能力。我们将分析DeepSeek-R1-Zero和DeepSeek-R1的训练过程、性能表现，以及它们在不同任务上的卓越表现。同时，我们还将讨论如何通过知识蒸馏技术，使更小的模型也能具备强大的推理能力。</description><link>https://weedge.us.kg/podcast/c371c85e08f246f9bffcef3eb573af31</link><guid>https://weedge.us.kg/podcast/c371c85e08f246f9bffcef3eb573af31</guid><pubDate>Fri, 24 Jan 2025 23:13:21 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2501.12948_2025-01-24_23-10-10.mp3" length="1859853" type="audio/mpeg" /><itunes:duration>07:44</itunes:duration></item><item><title>Hunyuan3D 2.0: 高分辨率纹理3D资产生成的扩散模型</title><description>本播客讨论Hunyuan3D 2.0，这是一个用于生成高分辨率纹理3D资产的先进大规模3D合成系统。该系统包括两个基础组件：一个大规模形状生成模型Hunyuan3D-DiT，以及一个大规模纹理合成模型Hunyuan3D-Paint。</description><link>https://weedge.us.kg/podcast/6a493e38b819427a8944c6ba8c35cdf8</link><guid>https://weedge.us.kg/podcast/6a493e38b819427a8944c6ba8c35cdf8</guid><pubDate>Fri, 24 Jan 2025 23:35:11 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2501.12202_2025-01-24_23-29-46.mp3" length="2666829" type="audio/mpeg" /><itunes:duration>11:06</itunes:duration></item><item><title>AI Radio FM - Technology Channel, Your Personal Generative AI Podcast</title><description>Discussing the Janus-Pro multimodal model.</description><link>https://weedge.us.kg/podcast/a54a3cbdf53d453888dee3b5df8b998d</link><guid>https://weedge.us.kg/podcast/a54a3cbdf53d453888dee3b5df8b998d</guid><pubDate>Tue, 28 Jan 2025 10:53:42 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/janus_pro_tech_report.pdf_2025-01-28_15-51-38.mp3" length="1486509" type="audio/mpeg" /><itunes:duration>06:11</itunes:duration></item><item><title>AI科技前沿：Janus多模态统一框架解析</title><description>欢迎来到AI Radio FM - 科技频道，您的专属生成式AI播客！今天，我们将深入探讨一项名为Janus的创新多模态框架。Janus通过解耦视觉编码，实现了多模态理解和生成任务的统一，为下一代多模态模型的发展提供了新思路。让我们一起揭开Janus的神秘面纱！</description><link>https://weedge.us.kg/podcast/4d5e3e302dc747b2a012d46fe3e6af77</link><guid>https://weedge.us.kg/podcast/4d5e3e302dc747b2a012d46fe3e6af77</guid><pubDate>Tue, 28 Jan 2025 08:15:59 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2410.13848_2025-01-28_16-11-31.mp3" length="1669389" type="audio/mpeg" /><itunes:duration>06:57</itunes:duration></item><item><title>JanusFlow: 统一多模态理解与生成框架</title><description>这是一个关于JanusFlow的播客，JanusFlow是一种强大的框架，它将图像理解和生成统一到一个模型中，通过整合自回归语言模型和校正流来实现。</description><link>https://weedge.us.kg/podcast/6f2e5a7a01924e35b7e4f068f930f200</link><guid>https://weedge.us.kg/podcast/6f2e5a7a01924e35b7e4f068f930f200</guid><pubDate>Tue, 28 Jan 2025 09:19:31 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2411.07975_2025-01-28_16-17-14.mp3" length="1313037" type="audio/mpeg" /><itunes:duration>05:28</itunes:duration></item><item><title>LLM Test-Time Compute Scaling: An In-Depth Analysis</title><description>A podcast discussing how to optimally scale test-time compute for Large Language Models (LLMs), focusing on improving both verifiers and the model&amp;#x27;s response distribution.</description><link>https://weedge.us.kg/podcast/96a10d4aa54645c19459a0709830ddad</link><guid>https://weedge.us.kg/podcast/96a10d4aa54645c19459a0709830ddad</guid><pubDate>Sat, 01 Feb 2025 18:18:38 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2408.03314_2025-02-01_18-15-37.mp3" length="1787373" type="audio/mpeg" /><itunes:duration>07:26</itunes:duration></item><item><title>Scaling LLM Test-Time Compute Optimally</title><description>A podcast discussing how to optimize the use of test-time computation for large language models (LLMs), focusing on strategies like searching against verifiers and refining proposal distributions to improve performance on challenging tasks.</description><link>https://weedge.us.kg/podcast/60e3e153ff1945f38122e467cfb565d5</link><guid>https://weedge.us.kg/podcast/60e3e153ff1945f38122e467cfb565d5</guid><pubDate>Sat, 01 Feb 2025 18:21:23 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2408.03314_2025-02-01_18-18-59.mp3" length="1731981" type="audio/mpeg" /><itunes:duration>07:12</itunes:duration></item><item><title>OmniHuman: 混合条件的人体动画模型</title><description>探讨OmniHuman，一种基于Diffusion Transformer的框架，通过混合运动相关条件来扩展数据，实现高度逼真的人体视频生成。</description><link>https://weedge.us.kg/podcast/9ef77a8c7ba343a39af36b30edcb6c50</link><guid>https://weedge.us.kg/podcast/9ef77a8c7ba343a39af36b30edcb6c50</guid><pubDate>Thu, 06 Feb 2025 10:53:42 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2502.01061v1_2025-02-06_10-51-22.mp3" length="1624557" type="audio/mpeg" /><itunes:duration>06:46</itunes:duration></item><item><title>Align-Anything: 多模态模型训练与语言反馈</title><description>本播客讨论了一种名为 Align-Anything 的新框架，该框架旨在通过利用人类反馈，尤其是语言反馈，来提升多模态模型的性能。该框架包括一个大规模的多模态数据集、一种新颖的对齐算法以及一个全面的评估工具。</description><link>https://weedge.us.kg/podcast/c0affdb51f6647c49da8fe60dcd765c3</link><guid>https://weedge.us.kg/podcast/c0affdb51f6647c49da8fe60dcd765c3</guid><pubDate>Thu, 06 Feb 2025 15:40:50 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2412.15838_2025-02-06_15-38-26.mp3" length="1838445" type="audio/mpeg" /><itunes:duration>07:39</itunes:duration></item><item><title>HumanOmni：以人为中心的视频理解大型视觉语音语言模型</title><description>深入探讨HumanOmni，一个为理解以人为中心的场景而设计的多模态大型语言模型。我们讨论了其数据集构建、模型架构以及在情感识别、面部表情理解和动作理解等任务上的表现。</description><link>https://weedge.us.kg/podcast/69531b3c404948889602c0375f1ee20d</link><guid>https://weedge.us.kg/podcast/69531b3c404948889602c0375f1ee20d</guid><pubDate>Fri, 07 Feb 2025 21:00:41 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2501.15111_2025-02-07_20-57-08.mp3" length="1943661" type="audio/mpeg" /><itunes:duration>08:05</itunes:duration></item><item><title>Omni-Emotion：通过详细的面部和音频建模扩展视频 MLLM 以进行多模态情感分析</title><description>本播客讨论了Omni-Emotion模型，该模型通过集成音频和细粒度面部信息来增强视频多模态大型语言模型（MLLM），从而在情感识别和推理任务中实现了最先进的性能。此外，本播客还讨论了用于训练Omni-Emotion模型的高质量自审阅和人工审阅情感数据集。</description><link>https://weedge.us.kg/podcast/007023af38a54b81aeb76738d62943bd</link><guid>https://weedge.us.kg/podcast/007023af38a54b81aeb76738d62943bd</guid><pubDate>Fri, 07 Feb 2025 21:22:04 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2501.09502_2025-02-07_21-19-26.mp3" length="1275117" type="audio/mpeg" /><itunes:duration>05:18</itunes:duration></item><item><title>Kimi k1.5: 基于强化学习的大语言模型扩展</title><description>本播客深入探讨了 Kimi 团队如何利用强化学习 (RL) 训练其最新的多模态大语言模型 Kimi k1.5。内容涵盖 RL 训练技术、多模态数据配方以及基础设施优化，重点关注长文本扩展和策略优化，以实现卓越的推理性能。</description><link>https://weedge.us.kg/podcast/37887f14b189480783f85f6137cfc449</link><guid>https://weedge.us.kg/podcast/37887f14b189480783f85f6137cfc449</guid><pubDate>Sat, 08 Feb 2025 11:31:42 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2501.12599_2025-02-08_11-29-18.mp3" length="2186349" type="audio/mpeg" /><itunes:duration>09:06</itunes:duration></item><item><title>Hibiki: 高保真同步语音到语音翻译</title><description>本播客深入探讨了 Hibiki，一种用于同步语音翻译的创新解码器模型。我们将讨论其架构、训练方法以及在法语-英语翻译任务中的卓越性能。此外，我们还将探讨其在设备上的实时部署潜力。</description><link>https://weedge.us.kg/podcast/68053ad2637a448db1d4a3165ca6f9a6</link><guid>https://weedge.us.kg/podcast/68053ad2637a448db1d4a3165ca6f9a6</guid><pubDate>Sat, 08 Feb 2025 16:21:35 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2502.03382_2025-02-08_16-19-21.mp3" length="1326477" type="audio/mpeg" /><itunes:duration>05:31</itunes:duration></item><item><title>VITA-1.5：迈向GPT-4o水平的实时视觉和语音交互</title><description>本期播客深入探讨VITA-1.5，一个旨在实现实时视觉和语音交互的多模态大型语言模型。我们将讨论其架构、训练策略以及在图像、视频和语音任务上的评估结果。</description><link>https://weedge.us.kg/podcast/c2228e5b5de84f17aeb721bec2e3f119</link><guid>https://weedge.us.kg/podcast/c2228e5b5de84f17aeb721bec2e3f119</guid><pubDate>Sun, 09 Feb 2025 15:23:36 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2501.01957_2025-02-09_15-21-31.mp3" length="1706637" type="audio/mpeg" /><itunes:duration>07:06</itunes:duration></item><item><title>LLaVA-OneVision: 易于实现的视觉任务迁移</title><description>探讨 LLaVA-OneVision，一个开源的大型多模态模型家族，通过整合 LLaVA-NeXT 博客系列中的数据、模型和视觉表示方面的见解而开发。实验结果表明，LLaVA-OneVision 是首个能够同时推动开放 LMM 在单图像、多图像和视频场景中性能边界的单一模型。该设计允许跨不同模态/场景进行强大的迁移学习，从而产生新的新兴能力。</description><link>https://weedge.us.kg/podcast/0cd04e58e9f74353872d7dec240ea4e4</link><guid>https://weedge.us.kg/podcast/0cd04e58e9f74353872d7dec240ea4e4</guid><pubDate>Sun, 09 Feb 2025 16:29:05 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2408.03326_2025-02-09_16-26-47.mp3" length="1375053" type="audio/mpeg" /><itunes:duration>05:43</itunes:duration></item><item><title>AI的苦涩教训：计算力至上</title><description>探讨AI研究中，通用方法如何凭借计算力超越人类知识，以及研究者们应该如何应对这一转变。</description><link>https://weedge.us.kg/podcast/f9709a4c3e384395a79af1ada13d28d9</link><guid>https://weedge.us.kg/podcast/f9709a4c3e384395a79af1ada13d28d9</guid><pubDate>Sun, 09 Feb 2025 19:01:44 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/BitterLesson.html_2025-02-09_18-59-57.mp3" length="1143021" type="audio/mpeg" /><itunes:duration>04:45</itunes:duration></item><item><title>Reinforcement Learning: An Engaging Podcast Discussion</title><description>A fast-paced and enthusiastic podcast conversation covering key concepts from the book &amp;quot;Reinforcement Learning: An Introduction,&amp;quot;
 tailored for audio consumption and enhanced understanding.</description><link>https://weedge.us.kg/podcast/9aedff3c4ca94390b5aae07386bb92e2</link><guid>https://weedge.us.kg/podcast/9aedff3c4ca94390b5aae07386bb92e2</guid><pubDate>Sun, 09 Feb 2025 20:27:16 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/SuttonBartoIPRLBook2ndEd.pdf_2025-02-09_20-25-03.mp3" length="1017261" type="audio/mpeg" /><itunes:duration>04:14</itunes:duration></item><item><title>Reinforcement Learning: A Comprehensive Exploration</title><description>A podcast delving into the core concepts, algorithms, and real-world applications of reinforcement learning, drawing from the renowned book by Sutton and Barto. This podcast will focus on making the content accessible and engaging for listeners interested in the field.</description><link>https://weedge.us.kg/podcast/7297a11622d941cab07395e76e762974</link><guid>https://weedge.us.kg/podcast/7297a11622d941cab07395e76e762974</guid><pubDate>Sun, 09 Feb 2025 20:35:17 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/SuttonBartoIPRLBook2ndEd.pdf_2025-02-09_20-33-20.mp3" length="1193229" type="audio/mpeg" /><itunes:duration>04:58</itunes:duration></item><item><title>InternVideo2.5：通过长文本和丰富上下文建模增强视频多模态大型语言模型</title><description>讨论 InternVideo2.5 如何通过长文本和丰富上下文建模来提升视频多模态大型语言模型（MLLM）的性能，包括其架构、训练方法以及在视频理解和特定视觉任务上的实验结果。</description><link>https://weedge.us.kg/podcast/5c5ae6a9774c48db90c38a5b7ecfac51</link><guid>https://weedge.us.kg/podcast/5c5ae6a9774c48db90c38a5b7ecfac51</guid><pubDate>Mon, 10 Feb 2025 10:04:46 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2501.12386_2025-02-10_10-02-49.mp3" length="1772397" type="audio/mpeg" /><itunes:duration>07:22</itunes:duration></item><item><title>InternVL 2.5：模型、数据和测试时扩展开放源代码多模态模型的性能边界</title><description>本播客讨论 InternVL 2.5，这是一种先进的多模态大型语言模型（MLLM）系列，它以 InternVL 2.0 为基础，在训练和测试策略以及数据质量方面进行了重大改进。通过对各种基准的广泛评估，包括多学科推理、文档理解、多图像/视频理解、现实世界理解、多模态幻觉检测、视觉定位、多语言能力和纯语言处理，InternVL 2.5 展现出具有竞争力的性能，可与 GPT-4o 和 Claude-3.5-Sonnet 等领先的商业模型相媲美。</description><link>https://weedge.us.kg/podcast/2d7824be1e7742319527136fd68af40f</link><guid>https://weedge.us.kg/podcast/2d7824be1e7742319527136fd68af40f</guid><pubDate>Mon, 10 Feb 2025 10:13:48 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2412.05271_2025-02-10_10-11-15.mp3" length="1752141" type="audio/mpeg" /><itunes:duration>07:17</itunes:duration></item><item><title>增强多模态大型语言模型的推理能力：混合偏好优化</title><description>探讨通过混合偏好优化增强多模态大型语言模型推理能力，结合数据和模型层面的改进，以提升模型在多模态推理任务中的性能。</description><link>https://weedge.us.kg/podcast/e0cb4ac4748842ef8adb2be27e86085f</link><guid>https://weedge.us.kg/podcast/e0cb4ac4748842ef8adb2be27e86085f</guid><pubDate>Mon, 10 Feb 2025 10:23:45 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2411.10442_2025-02-10_10-21-27.mp3" length="1470573" type="audio/mpeg" /><itunes:duration>06:07</itunes:duration></item><item><title>Mini-InternVL：一款灵活迁移的口袋多模态模型</title><description>本播客讨论了 Mini-InternVL，这是一款参数范围从 1B 到 4B 的多模态大型语言模型（MLLM），它仅用 5% 的参数实现了 90% 的性能。该模型具有统一的自适应框架，可以迁移并在自动驾驶、医学图像和遥感等下游任务中胜过专用模型。</description><link>https://weedge.us.kg/podcast/9dab16d47d6444e4b0231a3f98511219</link><guid>https://weedge.us.kg/podcast/9dab16d47d6444e4b0231a3f98511219</guid><pubDate>Mon, 10 Feb 2025 11:04:40 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2410.16261_2025-02-10_11-03-05.mp3" length="1086381" type="audio/mpeg" /><itunes:duration>04:31</itunes:duration></item><item><title>多模态奖励模型：IXC-2.5-Reward</title><description>探讨 InternLM-XComposer2.5-Reward (IXC-2.5-Reward)，一个用于大型视觉语言模型 (LVLM) 的多模态奖励模型，它通过强化学习或测试时缩放来提升生成质量。该模型在多模态基准测试中表现出色，并在强化学习训练、测试时缩放和数据清洗方面具有应用。</description><link>https://weedge.us.kg/podcast/923c350bd30d48c98fd783829263e55d</link><guid>https://weedge.us.kg/podcast/923c350bd30d48c98fd783829263e55d</guid><pubDate>Mon, 10 Feb 2025 11:14:08 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2501.12368_2025-02-10_11-11-35.mp3" length="2437293" type="audio/mpeg" /><itunes:duration>10:09</itunes:duration></item><item><title>MiniCPM-o 2.6: GPT-4o 级别的多模态大语言模型</title><description>探讨 MiniCPM-o 2.6，一个能在手机上运行，具备 GPT-4o 级别视觉、语音和多模态直播能力的多模态大语言模型。</description><link>https://weedge.us.kg/podcast/d8f3971d0695489fbff6f620d050135f</link><guid>https://weedge.us.kg/podcast/d8f3971d0695489fbff6f620d050135f</guid><pubDate>Mon, 10 Feb 2025 15:22:06 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/minicpm-o-2-6-en_2025-02-10_15-19-58.mp3" length="1471629" type="audio/mpeg" /><itunes:duration>06:07</itunes:duration></item><item><title>VoxInstruct: 统一多语编解码语言模型实现富有表现力的人工指令语音生成</title><description>探讨VoxInstruct，一种新型框架，它扩展了传统文本到语音的任务，使其能够直接从人类指令生成语音，从而提升语音生成的表现力和泛化能力。</description><link>https://weedge.us.kg/podcast/311c32657ce24d3d955dbf30401b3b4c</link><guid>https://weedge.us.kg/podcast/311c32657ce24d3d955dbf30401b3b4c</guid><pubDate>Mon, 10 Feb 2025 16:43:43 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2408.15676_2025-02-10_16-42-06.mp3" length="900717" type="audio/mpeg" /><itunes:duration>03:45</itunes:duration></item><item><title>大型语言模型基础</title><description>本播客讨论了大型语言模型（LLM）的基础知识，包括预训练方法、提示工程、对齐技术等。它涵盖了Transformer架构，自监督学习，以及如何将LLM用于各种NLP任务。</description><link>https://weedge.us.kg/podcast/0b4b248063724ac1851f861d464408c3</link><guid>https://weedge.us.kg/podcast/0b4b248063724ac1851f861d464408c3</guid><pubDate>Tue, 11 Feb 2025 10:13:48 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/Foundations of Large Language Models.pdf_2025-02-11_10-11-59.mp3" length="1126029" type="audio/mpeg" /><itunes:duration>04:41</itunes:duration></item><item><title>Seed-Music: 统一框架下的高质量可控音乐生成</title><description>探索 Seed-Music，一个旨在生成具有细粒度风格控制的高质量音乐的音乐生成和编辑系统套件。我们的统一框架利用自回归语言建模和扩散方法来支持两种关键的音乐创作工作流程：受控音乐生成和后期制作编辑。</description><link>https://weedge.us.kg/podcast/89039413a80049eb9db5b7b91167767c</link><guid>https://weedge.us.kg/podcast/89039413a80049eb9db5b7b91167767c</guid><pubDate>Tue, 11 Feb 2025 13:14:52 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2409.09214_2025-02-11_13-11-47.mp3" length="2622093" type="audio/mpeg" /><itunes:duration>10:55</itunes:duration></item><item><title>AI赋能视频创作：Goku模型解析</title><description>深入探讨Goku，一种基于流动模型的视频生成基础模型，及其在图像和视频联合生成方面的突破性进展。</description><link>https://weedge.us.kg/podcast/d6d0650bbdb24e7fb7114b7810ff2553</link><guid>https://weedge.us.kg/podcast/d6d0650bbdb24e7fb7114b7810ff2553</guid><pubDate>Tue, 11 Feb 2025 21:22:38 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2502.04896v2_2025-02-11_21-19-44.mp3" length="1581165" type="audio/mpeg" /><itunes:duration>06:35</itunes:duration></item><item><title>Zonos-v0.1 Beta 发布：新一代文本转语音模型</title><description>深入探讨Zyphra公司发布的Zonos-v0.1 Beta，一款具有高保真语音克隆功能的实时文本转语音模型。我们将分析其特性、定价、与其他模型的比较以及技术架构。</description><link>https://weedge.us.kg/podcast/6292903b8976438e9c9ff3cd30fdd60c</link><guid>https://weedge.us.kg/podcast/6292903b8976438e9c9ff3cd30fdd60c</guid><pubDate>Wed, 12 Feb 2025 19:46:52 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/beta-release-of-zonos-v0-1_2025-02-12_19-44-34.mp3" length="1363245" type="audio/mpeg" /><itunes:duration>05:40</itunes:duration></item><item><title>Sample-Efficient Reasoning with Test-Time Scaling: A Podcast Discussion</title><description>A podcast delving into the innovative s1-32B model, exploring its sample-efficient reasoning capabilities and test-time scaling techniques.</description><link>https://weedge.us.kg/podcast/8fe971dec55b43dca4133c141a84936b</link><guid>https://weedge.us.kg/podcast/8fe971dec55b43dca4133c141a84936b</guid><pubDate>Wed, 12 Feb 2025 20:25:47 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2501.19393_2025-02-12_20-23-25.mp3" length="1154157" type="audio/mpeg" /><itunes:duration>04:48</itunes:duration></item><item><title>s1: 简单测试时缩放</title><description>本播客讨论了一种新的语言建模方法，该方法使用额外的测试时计算来提高性能。我们介绍了 s1K，这是一个包含 1000 个问题的数据集，并开发了预算强制来控制测试时计算。</description><link>https://weedge.us.kg/podcast/0902c83288224e26bc57055130363542</link><guid>https://weedge.us.kg/podcast/0902c83288224e26bc57055130363542</guid><pubDate>Wed, 12 Feb 2025 20:51:54 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2501.19393_2025-02-12_20-48-41.mp3" length="1437069" type="audio/mpeg" /><itunes:duration>05:59</itunes:duration></item><item><title>Mamba: 线性时间序列建模与选择性状态空间</title><description>深入探讨Mamba，一种无需注意力的架构，它通过选择性状态空间实现在语言、音频和基因组等多种模式下的卓越性能。</description><link>https://weedge.us.kg/podcast/0507b82e7b504217b8663a97acf4237b</link><guid>https://weedge.us.kg/podcast/0507b82e7b504217b8663a97acf4237b</guid><pubDate>Sun, 16 Feb 2025 11:07:57 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2312.00752_2025-02-16_11-06-16.mp3" length="1441197" type="audio/mpeg" /><itunes:duration>06:00</itunes:duration></item><item><title>Transformer 和 SSM 的结构化状态空间对偶性</title><description>探讨 Transformer 和状态空间模型（SSM）之间联系的播客，重点介绍 SSM 的优势和高效算法，以及新的 Mamba-2 架构。</description><link>https://weedge.us.kg/podcast/4c5c62dd468b4294aacad74f61ec6c41</link><guid>https://weedge.us.kg/podcast/4c5c62dd468b4294aacad74f61ec6c41</guid><pubDate>Sun, 16 Feb 2025 11:11:13 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/Transformers are SSMs.pdf_2025-02-16_11-09-12.mp3" length="1589997" type="audio/mpeg" /><itunes:duration>06:37</itunes:duration></item><item><title>AI Radio FM - 音乐生成技术</title><description>本次播客深入探讨了MusicLM，一个能根据文本描述生成高保真音乐的模型。我们将讨论MusicLM的技术细节、实验结果、以及它与先前系统的比较。此外，我们还将介绍MusicCaps数据集，并探讨MusicLM在音乐创作领域的潜在应用和风险。</description><link>https://weedge.us.kg/podcast/322164f8ac5342688a4e016bfec0b5d4</link><guid>https://weedge.us.kg/podcast/322164f8ac5342688a4e016bfec0b5d4</guid><pubDate>Tue, 18 Feb 2025 12:38:26 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2301.11325_2025-02-18_12-36-40.mp3" length="991245" type="audio/mpeg" /><itunes:duration>04:07</itunes:duration></item><item><title>MuLan：音乐音频与自然语言的联合嵌入</title><description>本次播客深入探讨了MuLan模型，这是一个连接音乐音频和自然语言描述的联合嵌入模型。我们讨论了它的架构、训练数据、应用以及在音乐信息检索任务中的表现。</description><link>https://weedge.us.kg/podcast/e563136db05b4e59ac7b2a6468431182</link><guid>https://weedge.us.kg/podcast/e563136db05b4e59ac7b2a6468431182</guid><pubDate>Tue, 18 Feb 2025 12:45:14 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2208.12415_2025-02-18_12-43-23.mp3" length="764109" type="audio/mpeg" /><itunes:duration>03:10</itunes:duration></item><item><title>AudioLM：音频生成的语言模型方法</title><description>我们介绍AudioLM，一个用于高质量音频生成并具有长期一致性的框架。AudioLM将输入音频映射到一系列离散标记，并将音频生成视为在此表示空间中的语言建模任务。</description><link>https://weedge.us.kg/podcast/cb5640b084774c7487ad8edbbe9297ad</link><guid>https://weedge.us.kg/podcast/cb5640b084774c7487ad8edbbe9297ad</guid><pubDate>Tue, 18 Feb 2025 12:53:09 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2209.03143_2025-02-18_12-50-37.mp3" length="1003533" type="audio/mpeg" /><itunes:duration>04:10</itunes:duration></item><item><title>AI Radio FM - Technology Channel</title><description>深入探讨Step-Audio，首个生产就绪的开源智能语音交互框架。</description><link>https://weedge.us.kg/podcast/f8ba00df1025479890b5f7e59b3c38e2</link><guid>https://weedge.us.kg/podcast/f8ba00df1025479890b5f7e59b3c38e2</guid><pubDate>Tue, 18 Feb 2025 15:12:39 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/Step-Audio.pdf_2025-02-18_15-10-44.mp3" length="1268397" type="audio/mpeg" /><itunes:duration>05:16</itunes:duration></item><item><title>AI Radio FM - 科技频道</title><description>深入探讨原生稀疏注意力机制（NSA）在长上下文建模中的应用和优势。</description><link>https://weedge.us.kg/podcast/92a9622436754bfc9585dbce037e8cf2</link><guid>https://weedge.us.kg/podcast/92a9622436754bfc9585dbce037e8cf2</guid><pubDate>Tue, 18 Feb 2025 16:14:34 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2502.11089_2025-02-18_16-12-29.mp3" length="956109" type="audio/mpeg" /><itunes:duration>03:58</itunes:duration></item><item><title>AI Radio FM - Technology Channel</title><description>深入探讨Step-Video-T2V技术报告，涵盖视频基础模型、模型架构、训练策略、系统优化及未来发展方向。</description><link>https://weedge.us.kg/podcast/4cb36309f8b64cf2acb7d96837356454</link><guid>https://weedge.us.kg/podcast/4cb36309f8b64cf2acb7d96837356454</guid><pubDate>Wed, 19 Feb 2025 09:37:08 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2502.10248_2025-02-19_09-34-46.mp3" length="1198701" type="audio/mpeg" /><itunes:duration>04:59</itunes:duration></item><item><title>AI Radio FM - 揭秘LUCY：情感、自然、更智能的语音交互</title><description>本期播客深入探讨了腾讯优图实验室的最新研究成果LUCY，一个在情感控制、自然度和信息丰富度方面均有显著提升的端到端语音模型。通过精心策划的合成训练数据，LUCY不仅能理解并响应用户的情感，还能以自然流畅的风格进行对话，并利用外部工具回答实时问题。</description><link>https://weedge.us.kg/podcast/cc6f80060dfc491c99e3b2bca1b0a633</link><guid>https://weedge.us.kg/podcast/cc6f80060dfc491c99e3b2bca1b0a633</guid><pubDate>Wed, 19 Feb 2025 11:29:14 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/LUCY- Linguistic Understanding and Control Yielding Early Stage of Her.pdf_2025-02-19_11-26-12.mp3" length="1394829" type="audio/mpeg" /><itunes:duration>05:48</itunes:duration></item><item><title>AI Radio FM - 深入探索Nomic Embed v2：首款混合专家文本嵌入模型</title><description>本期节目我们将深入探讨Nomic AI发布的Nomic Embed v2，这是业界首款通用混合专家（MoE）文本嵌入模型。我们将讨论其架构、训练方法、性能表现以及与同类模型的比较，并分析MoE架构在文本嵌入领域的有效性。</description><link>https://weedge.us.kg/podcast/198c728c634e4694acb5fbe6468ed558</link><guid>https://weedge.us.kg/podcast/198c728c634e4694acb5fbe6468ed558</guid><pubDate>Wed, 19 Feb 2025 12:48:31 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2502.07972v2_2025-02-19_12-46-28.mp3" length="1344333" type="audio/mpeg" /><itunes:duration>05:35</itunes:duration></item><item><title>AI解读SyncSpeech：低延迟高效双流文本转语音</title><description>本期播客深入探讨SyncSpeech，一种基于时间掩码Transformer的新型双流文本转语音（TTS）模型。SyncSpeech能够同步处理流式文本输入并生成语音，实现低延迟和高效率。</description><link>https://weedge.us.kg/podcast/4e2545d416bd452eb17f62a8bcdffcd3</link><guid>https://weedge.us.kg/podcast/4e2545d416bd452eb17f62a8bcdffcd3</guid><pubDate>Wed, 19 Feb 2025 13:08:07 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2502.11094v1_2025-02-19_13-05-33.mp3" length="861645" type="audio/mpeg" /><itunes:duration>03:35</itunes:duration></item><item><title>AI Radio FM - Technology Channel</title><description>深度解析MinMo：一款为无缝语音交互打造的多模态大型语言模型</description><link>https://weedge.us.kg/podcast/5cb0aec3deb14f9e88248683db92c5b8</link><guid>https://weedge.us.kg/podcast/5cb0aec3deb14f9e88248683db92c5b8</guid><pubDate>Wed, 19 Feb 2025 13:20:43 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2501.06282_2025-02-19_13-18-37.mp3" length="1009197" type="audio/mpeg" /><itunes:duration>04:12</itunes:duration></item><item><title>AI Radio FM - Technology Channel</title><description>深入探讨MoBA（Mixture of Block Attention）技术，这是一种为长上下文LLM设计的新型注意力机制。</description><link>https://weedge.us.kg/podcast/ed5dea833332476fa026ce1061bef43d</link><guid>https://weedge.us.kg/podcast/ed5dea833332476fa026ce1061bef43d</guid><pubDate>Wed, 19 Feb 2025 21:54:59 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/MoBA_Tech_Report.pdf_2025-02-19_21-51-44.mp3" length="1019373" type="audio/mpeg" /><itunes:duration>04:14</itunes:duration></item><item><title>AI Radio FM - Muon优化器深度解析</title><description>本期播客深入探讨了Muon优化器在大规模语言模型训练中的应用。Moonshot AI团队分享了他们如何通过添加权重衰减和调整参数更新尺度，成功将Muon扩展到3B/16B参数的MoE模型Moonlight的训练中。实验表明，与AdamW相比，Muon在计算效率上提高了约2倍。此外，播客还讨论了Muon的分布式实现，以及在预训练和监督微调阶段的表现。</description><link>https://weedge.us.kg/podcast/64bab28419694b44bc6832ae8e5b560d</link><guid>https://weedge.us.kg/podcast/64bab28419694b44bc6832ae8e5b560d</guid><pubDate>Sun, 23 Feb 2025 14:17:46 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/Moonlight.pdf_2025-02-23_14-15-08.mp3" length="801741" type="audio/mpeg" /><itunes:duration>03:20</itunes:duration></item><item><title>AI Radio FM - 高效人工智能实践</title><description>本期播客讨论了在工业应用中训练和部署高效大型语言模型（LLMs）的实用方法。主题包括知识蒸馏、模型压缩技术（如量化和剪枝），以及在实际部署中优化硬件和提高推理速度的策略。</description><link>https://weedge.us.kg/podcast/c0cbeb80ba5747cfade878e8e70961b3</link><guid>https://weedge.us.kg/podcast/c0cbeb80ba5747cfade878e8e70961b3</guid><pubDate>Mon, 24 Feb 2025 18:05:50 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2502.14305_2025-02-24_18-03-33.mp3" length="995757" type="audio/mpeg" /><itunes:duration>04:08</itunes:duration></item><item><title>AI Radio FM - Fire-Flyer AI-HPC：深度学习的软硬件协同设计</title><description>本期播客深入探讨了DeepSeek-AI的Fire-Flyer AI-HPC架构，这是一个专为深度学习设计的、具有成本效益的软硬件协同设计框架。讨论涵盖了从硬件选择、网络拓扑到软件优化（如HFReduce和HaiScale）的各个方面，以及如何通过这些创新实现高性能和低成本。</description><link>https://weedge.us.kg/podcast/e622417d05e34e3e8a675163b7d5d198</link><guid>https://weedge.us.kg/podcast/e622417d05e34e3e8a675163b7d5d198</guid><pubDate>Tue, 25 Feb 2025 10:46:14 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2408.14158_2025-02-25_10-44-11.mp3" length="1359597" type="audio/mpeg" /><itunes:duration>05:39</itunes:duration></item><item><title>AI解读Vision Mamba：视觉表示学习新星</title><description>本期播客深入探讨Vision Mamba (Vim)，一种新型通用视觉骨干网络，它采用双向Mamba块进行图像序列标记，并通过双向状态空间模型压缩视觉表示。Vim在ImageNet分类、COCO目标检测和ADE20k语义分割任务中表现出色，同时计算和内存效率显著提高。</description><link>https://weedge.us.kg/podcast/64dca8fe2f7c4f49bfab81db92917f6d</link><guid>https://weedge.us.kg/podcast/64dca8fe2f7c4f49bfab81db92917f6d</guid><pubDate>Wed, 26 Feb 2025 22:41:45 +0000</pubDate><enclosure url="https://pub-f8da0a7ab3e74cc8a8081b2d4b8be851.r2.dev/2401.09417_2025-02-26_22-39-17.mp3" length="1012461" type="audio/mpeg" /><itunes:duration>04:13</itunes:duration></item></channel></rss>